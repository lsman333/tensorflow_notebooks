{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","toc_visible":true,"mount_file_id":"1YdQjVQo8MScHzukSQHYKGEioSoLjbJBS","authorship_tag":"ABX9TyN8LCqBUP8oH8AnT3+38sWz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"7fuaXq09eENT","executionInfo":{"status":"ok","timestamp":1731040774790,"user_tz":300,"elapsed":173021,"user":{"displayName":"Mark","userId":"05293542057377705486"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6c12778c-7786-4dff-932c-e8c2e55da2a3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: tensorflow 2.17.0\n","Uninstalling tensorflow-2.17.0:\n","  Would remove:\n","    /usr/local/bin/import_pb_to_tensorboard\n","    /usr/local/bin/saved_model_cli\n","    /usr/local/bin/tensorboard\n","    /usr/local/bin/tf_upgrade_v2\n","    /usr/local/bin/tflite_convert\n","    /usr/local/bin/toco\n","    /usr/local/bin/toco_from_protos\n","    /usr/local/lib/python3.10/dist-packages/tensorflow-2.17.0.dist-info/*\n","    /usr/local/lib/python3.10/dist-packages/tensorflow/*\n","Proceed (Y/n)? y\n","  Successfully uninstalled tensorflow-2.17.0\n","Collecting tensorflow==2.15.0\n","  Downloading tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.12.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (18.1.1)\n","Collecting ml-dtypes~=0.2.0 (from tensorflow==2.15.0)\n","  Downloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.26.4)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (24.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (4.12.2)\n","Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.15.0)\n","  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.37.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.64.1)\n","Collecting tensorboard<2.16,>=2.15 (from tensorflow==2.15.0)\n","  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n","Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow==2.15.0)\n","  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n","Collecting keras<2.16,>=2.15.0 (from tensorflow==2.15.0)\n","  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.44.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.7)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.32.3)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.6)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.5.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2024.8.30)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.2)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.6.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.2)\n","Downloading tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, ml-dtypes, keras, tensorboard, tensorflow\n","  Attempting uninstall: wrapt\n","    Found existing installation: wrapt 1.16.0\n","    Uninstalling wrapt-1.16.0:\n","      Successfully uninstalled wrapt-1.16.0\n","  Attempting uninstall: ml-dtypes\n","    Found existing installation: ml-dtypes 0.4.1\n","    Uninstalling ml-dtypes-0.4.1:\n","      Successfully uninstalled ml-dtypes-0.4.1\n","  Attempting uninstall: keras\n","    Found existing installation: keras 3.4.1\n","    Uninstalling keras-3.4.1:\n","      Successfully uninstalled keras-3.4.1\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.17.0\n","    Uninstalling tensorboard-2.17.0:\n","      Successfully uninstalled tensorboard-2.17.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorstore 0.1.67 requires ml-dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n","tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.15.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed keras-2.15.0 ml-dtypes-0.2.0 tensorboard-2.15.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 wrapt-1.14.1\n","/bin/bash: line 1: tensorflow: command not found\n"]}],"source":["#We need to install tf version 2.15 for compatibility with this notebook (written in March 2024).\n","!pip uninstall tensorflow\n","!pip install tensorflow==2.15.0\n","!tensorflow --version"]},{"cell_type":"markdown","source":["# Transfer Learning with TensorFlow part 3 - Scaling Up (Food Vision Mini)\n","\n","We've seen the power of transfer learning ,feature extraction, and fine tuning.  Now it's time to scale up to all of the classes in Food101... 101 total classes of food.  Our goal is to beat the original Food101 paper with 10% of the training data, leveraging the power of deep learning.\n","\n","Original Food101 paper: https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/static/bossard_eccv14_food-101.pdf\n","\n","Our baseline to beat is 50.76% accuracy across 101 classes."],"metadata":{"id":"JqRQQN-yeKz3"}},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"07AWCnp6e7dx","executionInfo":{"status":"ok","timestamp":1731040775088,"user_tz":300,"elapsed":302,"user":{"displayName":"Mark","userId":"05293542057377705486"}},"outputId":"06b83ccb-acf7-483e-87e2-551c7c4d051d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Nov  8 04:39:34 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   40C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","source":["## Creating helper functions\n","\n","In previous notebooks we have created a series of helper functions to help us in the task.  Let's download them."],"metadata":{"id":"CFC6jVc5fMGy"}},{"cell_type":"code","source":["!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"trz29JKSfb8u","executionInfo":{"status":"ok","timestamp":1731040775088,"user_tz":300,"elapsed":5,"user":{"displayName":"Mark","userId":"05293542057377705486"}},"outputId":"50f0b34a-4738-4e63-8c04-62923790afa0"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-11-08 04:39:34--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 10246 (10K) [text/plain]\n","Saving to: ‘helper_functions.py’\n","\n","helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n","\n","2024-11-08 04:39:34 (115 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n","\n"]}]},{"cell_type":"code","source":["# Import series of helper functions for our notebook\n","from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, compare_historys, walk_through_dir\n","\n"],"metadata":{"id":"ASoTpPWafhdx","executionInfo":{"status":"ok","timestamp":1731040781042,"user_tz":300,"elapsed":5956,"user":{"displayName":"Mark","userId":"05293542057377705486"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## 101 Food Classes: working with less data\n","\n","Our goal is to beat the original Food101 paper with 10% of the training data.  Let's download it.\n","\n","The data we're downloading comes from the original Food101 data set, but has been preprocessed using the image_data_modification notebook."],"metadata":{"id":"5DjAzgExf449"}},{"cell_type":"code","source":["!wget https://storage.googleapis.com/ztm_tf_course/food_vision/101_food_classes_10_percent.zip\n","unzip_data(\"101_food_classes_10_percent.zip\")\n","\n","train_dir = \"101_food_classes_10_percent/train/\"\n","test_dir = \"101_food_classes_10_percent/test/\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E7V43GGYgYf_","outputId":"c6c9f016-1063-4abd-ef0b-3f4ac0ccecf7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-11-08 04:39:40--  https://storage.googleapis.com/ztm_tf_course/food_vision/101_food_classes_10_percent.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.68.207, 64.233.170.207, 142.251.175.207, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.68.207|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1625420029 (1.5G) [application/zip]\n","Saving to: ‘101_food_classes_10_percent.zip’\n","\n","ent.zip              47%[========>           ] 737.93M  14.8MB/s    eta 54s    "]}]},{"cell_type":"code","source":["# How many images classes are there?\n","walk_through_dir(\"101_food_classes_10_percent\")"],"metadata":{"id":"uIm6ZPBBgyrn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Setup data inputs\n","import tensorflow as tf\n","IMG_SIZE=(224,224)\n","train_data_all_10_percent = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n","                                                                                label_mode=\"categorical\",\n","                                                                                image_size=IMG_SIZE)\n","\n","test_data_all_10_percent = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n","                                                                               label_mode=\"categorical\",\n","                                                                               image_size=IMG_SIZE,\n","                                                                               shuffle=False)     #don't shuffle test data for prediction analysis."],"metadata":{"id":"sFX5mEsXiJaG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Train a big dog model with transfer learning on 10% of 101 food classes\n","\n","Here are the steps we're going to take:\n","* Create a ModelCheckpoint callback\n","* Create a data augmentation layer to build data augmentation right into the model\n","* Build a headless (no top layer) Functional EfficientNetB0 backboned-model (we'll create our own output layer)\n","* Compile our model\n","* Feature extract for 5 full passes (5 passes on the train dataset and validate on 15% of the test data to save epoch time)"],"metadata":{"id":"-NgUyz2MbPCh"}},{"cell_type":"code","source":["# Create CheckPoint callback\n","checkpoint_path = \"101_classes_10_percent_data_model_checkpoint\"\n","checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n","                                                         save_weights_only=True,\n","                                                         monitor=\"val_accuracy\",\n","                                                         save_best_only=True)"],"metadata":{"id":"O3v2DrsPcFVR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create data augmentation layer to incorporate it right into our model\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers.experimental import preprocessing\n","from tensorflow.keras.models import Sequential\n","\n","# Setup data augmentation\n","data_augmentation = Sequential([\n","    preprocessing.RandomFlip(\"horizontal\"),\n","    preprocessing.RandomRotation(0.2),\n","    preprocessing.RandomHeight(0.2),\n","    preprocessing.RandomWidth(0.2),\n","    preprocessing.RandomZoom(0.2),\n","    #preprocessing.Rescale(1/255.), #rescale inputs of images to between 0 and 1, required for models like ResNet50\n","], name=\"data_augmentation\")"],"metadata":{"id":"0fvU7kAseC8Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Setup the base model and freeze its layers (this will extract features)\n","base_model=tf.keras.applications.EfficientNetB0(include_top=False)\n","base_model.trainable = False\n","\n","#Setup model architecture with trainable top layers\n","inputs = layers.Input(shape=(224,224,3), name=\"input_layer\")\n","x = data_augmentation(inputs) # augment images (only happens during training phase)\n","x = base_model(x, training=False) # This will put the base model into inference mode so weights which need to stay frozen stay frozen\n","x = layers.GlobalAveragePooling2D(name=\"global_avg_pool_layer\")(x)\n","outputs = layers.Dense(len(train_data_all_10_percent.class_names), activation=\"softmax\", name=\"output_layer\")(x)\n","model = tf.keras.Model(inputs, outputs)"],"metadata":{"id":"Tp6Z9w0pffIh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get a summary of model we've created\n","model.summary()"],"metadata":{"id":"AdsT8w38iNMp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["initial_epochs = 5"],"metadata":{"id":"C1BEO73M0gaI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compile the model\n","model.compile(loss=\"categorical_crossentropy\",\n","              optimizer=tf.keras.optimizers.Adam(),\n","              metrics=\"accuracy\",)\n","\n","\n","\n","history_all_classes_10_percent = model.fit(train_data_all_10_percent,\n","                    batch_size=32,\n","                    epochs=initial_epochs,\n","                    validation_data=test_data_all_10_percent,\n","                    validation_steps=int(0.15 * len(test_data_all_10_percent)),\n","                    callbacks=[checkpoint_callback])"],"metadata":{"id":"aiytrjNoi6RB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["feature_extraction_results = model.evaluate(test_data_all_10_percent)\n","feature_extraction_results"],"metadata":{"id":"s6PAA1APoAqu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_loss_curves(history_all_classes_10_percent)"],"metadata":{"id":"Izwz3XzFmIst"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["** QUestion: ** What do these two curves suggest?  Hint: Ideally these two curves should be very similar to each other.  IF not, it may suggest our model is overfitting... performing too well on training data and not generalizing to unseen data.\n"],"metadata":{"id":"_TNRVH-ZogIA"}},{"cell_type":"markdown","source":["## Fine Tuning"],"metadata":{"id":"ljDujUKeFEOJ"}},{"cell_type":"code","source":["# Freeze all of the layers in the base model\n","base_model.trainable = False\n","\n","# Unfreeze last 5\n","for layer in base_model.layers[-5:]:\n","  layer.trainable = True"],"metadata":{"id":"mpPfQslBFRmr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Recompile model with lower learning rate (it's typically best practice the LR when fine-tuning by 10x)\n","model.compile(loss=\"categorical_crossentropy\",\n","              optimizer=tf.keras.optimizers.Adam(lr=0.0001), #learning rate lowered by 10x\n","              metrics=\"accuracy\")\n","\n","# What layers in the model are trainable\n","for layer in model.layers:\n","  print(layer.name, layer.trainable, )"],"metadata":{"id":"65FiCSCbG3dy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check which layers are trainable in our base model\n","for layer_number, layer in enumerate(model.layers[2].layers):\n","  print (layer_number, layer.name, layer.trainable)"],"metadata":{"id":"PDwhL8xbHzx7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Fine tune for another 5 epochs\n","fine_tuning_epochs = initial_epochs + 5\n","\n","history_fine_all_data_10_percent = model.fit(train_data_all_10_percent,\n","                                             batch_size=32,\n","                                             epochs=fine_tuning_epochs,\n","                                             validation_data=test_data_all_10_percent,\n","                                             validation_steps=int(0.15 * len(test_data_all_10_percent)),\n","                                             initial_epoch=history_all_classes_10_percent.epoch[-1])"],"metadata":{"id":"HLtBE6l30DXD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate on the whole test data\n","all_classes_10_percent_fine_tune_results = model.evaluate(test_data_all_10_percent)"],"metadata":{"id":"0Mgip9zi4b5M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_classes_10_percent_fine_tune_results"],"metadata":{"id":"KVIAVbc14pSW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compare histories of feature extraction model with fine tuning model\n","compare_historys(original_history=history_all_classes_10_percent,\n","                 new_history=history_fine_all_data_10_percent,\n","                 initial_epochs=5)"],"metadata":{"id":"BE0SNZ9Q5paD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Saving and loading our model\n","To use our model in an external application, we will need to save it and export it somewhere\n"],"metadata":{"id":"mc4gXjYI8H6q"}},{"cell_type":"code","source":["# Save our fine-tuned model\n","model.save(\"drive/MyDrive/TensorFlowCourse/101_food_classes_10_percent_saved_big_dog_model\")"],"metadata":{"id":"Y95xFcmf8QPQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load and evaluate saved model\n","loaded_model = tf.keras.models.load_model(\"drive/MyDrive/TensorFlowCourse/101_food_classes_10_percent_saved_big_dog_model\")"],"metadata":{"id":"Ol1m7RSr885R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate loaded model and compare performance to pre-saved model\n","loaded_model_results = loaded_model.evaluate(test_data_all_10_percent)\n","loaded_model_results"],"metadata":{"id":"_W1a8K-p9Tyn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The results from our loaded model (above) should be very similar to the results below\n","all_classes_10_percent_fine_tune_results"],"metadata":{"id":"mJwO8PEU9kyH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluating the performance of the big dog model across all different classes\n","\n","Let's make some predictions, visualize them, and then later find out which predictions were the \"most\" wrong"],"metadata":{"id":"33QsRWIbHgsJ"}},{"cell_type":"code","source":["import tensorflow as tf\n","!wget https://storage.googleapis.com/ztm_tf_course/food_vision/06_101_food_class_10_percent_saved_big_dog_model.zip\n","\n"],"metadata":{"id":"QLv087VMHdGj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["unzip_data(\"/content/06_101_food_class_10_percent_saved_big_dog_model.zip\")"],"metadata":{"id":"EdKZTBjQITwx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load in saved model (one that was saved earlier) so that all predictions are similar\n","loaded_model = tf.keras.models.load_model(\"/content/06_101_food_class_10_percent_saved_big_dog_model\")"],"metadata":{"id":"rqy675PNIgoU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate loaded model (the one we just downloaded) on test data\n","results_downloaded_model = model.evaluate(test_data_all_10_percent)\n","results_downloaded_model"],"metadata":{"id":"sJkGyGdPJK9M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Making predictions with our trained model\n"],"metadata":{"id":"eAumEkaZKayS"}},{"cell_type":"code","source":["# Make predictions with our model\n","pred_probs = model.predict(test_data_all_10_percent,\n","                           verbose=1) # Set verbosity to see how long is left"],"metadata":{"id":"hqAsr1Z4KdV6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# How many predictions are there?\n","len(pred_probs)"],"metadata":{"id":"8DBq89DhLOdL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# What's the shape of our predictions?\n","pred_probs.shape"],"metadata":{"id":"03S6JSBaLbf3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Let's see what the first 10 predictions look like\n","pred_probs[:10]"],"metadata":{"id":"La9jYwTxLpA2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# What does the first prediction probability array look like?\n","pred_probs[0], len(pred_probs[0]), sum(pred_probs[0])"],"metadata":{"id":"CMMOjuBZL3KI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Our model outputs a prediction probability array with n-number of variables where n is the number of classes of each sample passed to the predict method."],"metadata":{"id":"miqjMp5wM7WR"}},{"cell_type":"code","source":["# We get one probability prediction per class (in our case there's 101 prediction probabilities)\n","print(f\"Number of prediction probabilities for sample 0: {len(pred_probs[0])}\")\n","print(f\"What prediction probability sample 0 looks like: \\n {pred_probs[0]}\")\n","print(f\"The class with the highest predicted probability by the model for sample 0: {pred_probs[0].argmax()}\")"],"metadata":{"id":"0NmWBUAMNgAM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get the pred classes of each label\n","pred_classes = pred_probs.argmax(axis=1)\n","\n","# How do they look?\n","pred_classes[:10]"],"metadata":{"id":"J0Cfut9xPDp1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# How many pred classes do we have?\n","len(pred_classes)"],"metadata":{"id":"OXOGXVRZPUqe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_data_all_10_percent.class_names[pred_classes[9]]"],"metadata":{"id":"SsmChxZvP490"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now we've got a predictions array of all our model's predictions.  To evaluate them we need to compare them to the original test dataset labels."],"metadata":{"id":"w5dsHvtYTouo"}},{"cell_type":"code","source":["# To get our test labels, we need to unravel our test_data BatchDataSet\n","y_labels = []\n","test_data_all_10_percent\n","for images, labels in test_data_all_10_percent.unbatch():\n","  y_labels.append(labels.numpy().argmax()) # currently test labels look like [0,0,0,1,0,...] we want the index value where 1 occurs\n","y_labels[:10] # look at the first 10\n"],"metadata":{"id":"U2n06g5KT2rS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(y_labels)"],"metadata":{"id":"5RXWXde_VOlb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(test_data_all_10_percent)"],"metadata":{"id":"iA-SBvQuUWul"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluating our model's predicitons\n","One way to predict if our model's predictions array is in the same order as our test labels array is to find the accuracy score."],"metadata":{"id":"YdR__Js5V87d"}},{"cell_type":"code","source":["results_downloaded_model"],"metadata":{"id":"tS5mt5R8V9vz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Let's try scikit-learn's accuracy score function and see what it comes up with\n","from sklearn.metrics import accuracy_score\n","sklearn_accuracy = accuracy_score(y_true=y_labels,\n","                                  y_pred=pred_classes)\n","sklearn_accuracy"],"metadata":{"id":"bXauT2LEWTcE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Does this metric come close to our model's evaluate results?\n","import numpy as np\n","np.isclose(results_downloaded_model[1], sklearn_accuracy)"],"metadata":{"id":"n2LhU2UUWxJ1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Let's get visual: making a confusion matrix"],"metadata":{"id":"n7Nk4DW4Y4Tl"}},{"cell_type":"code","source":["# Get a list of class names\n","class_names = test_data_all_10_percent.class_names\n","class_names"],"metadata":{"id":"CNZ59qg6ZQrK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(y_labels)"],"metadata":{"id":"3Nt216tKaB9u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# We need to make some changes to our make_confusion_matrix to make our x-labels print vertically\n","import itertools\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.metrics import confusion_matrix\n","\n","def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15, norm=False, savefig=False):\n","  \"\"\"Makes a labelled confusion matrix comparing predictions and ground truth labels.\n","\n","  If classes is passed, confusion matrix will be labelled, if not, integer class values\n","  will be used.\n","\n","  Args:\n","    y_true: Array of truth labels (must be same shape as y_pred).\n","    y_pred: Array of predicted labels (must be same shape as y_true).\n","    classes: Array of class labels (e.g. string form). If `None`, integer labels are used.\n","    figsize: Size of output figure (default=(10, 10)).\n","    text_size: Size of output figure text (default=15).\n","    norm: normalize values or not (default=False).\n","    savefig: save confusion matrix to file (default=False).\n","\n","  Returns:\n","    A labelled confusion matrix plot comparing y_true and y_pred.\n","\n","  Example usage:\n","    make_confusion_matrix(y_true=test_labels, # ground truth test labels\n","                          y_pred=y_preds, # predicted labels\n","                          classes=class_names, # array of class label names\n","                          figsize=(15, 15),\n","                          text_size=10)\n","  \"\"\"\n","  # Create the confustion matrix\n","  cm = confusion_matrix(y_true, y_pred)\n","  cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n","  n_classes = cm.shape[0] # find the number of classes we're dealing with\n","\n","  # Plot the figure and make it pretty\n","  fig, ax = plt.subplots(figsize=figsize)\n","  cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n","  fig.colorbar(cax)\n","\n","  # Are there a list of classes?\n","  if classes:\n","    labels = classes\n","  else:\n","    labels = np.arange(cm.shape[0])\n","\n","  # Label the axes\n","  ax.set(title=\"Confusion Matrix\",\n","         xlabel=\"Predicted label\",\n","         ylabel=\"True label\",\n","         xticks=np.arange(n_classes), # create enough axis slots for each class\n","         yticks=np.arange(n_classes),\n","         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n","         yticklabels=labels)\n","\n","  # Make x-axis labels appear on bottom\n","  ax.xaxis.set_label_position(\"bottom\")\n","  ax.xaxis.tick_bottom()\n","\n","  ###Changed (plot x-labels vertically):###\n","  plt.xticks(rotation=70, fontsize=text_size)\n","  plt.yticks(fontsize=text_size)\n","\n","  # Set the threshold for different colors\n","  threshold = (cm.max() + cm.min()) / 2.\n","\n","  # Plot the text on each cell\n","  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","    if norm:\n","      plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n","              horizontalalignment=\"center\",\n","              color=\"white\" if cm[i, j] > threshold else \"black\",\n","              size=text_size)\n","    else:\n","      plt.text(j, i, f\"{cm[i, j]}\",\n","              horizontalalignment=\"center\",\n","              color=\"white\" if cm[i, j] > threshold else \"black\",\n","              size=text_size)\n","\n","  # Save the figure to the current working directory\n","  if savefig:\n","    fig.savefig(\"confusion_matrix.png\")"],"metadata":{"id":"UO90lKEzbevg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#from helper_functions import make_confusion_matrix\n","make_confusion_matrix(y_true=y_labels,\n","                      y_pred=pred_classes,\n","                      classes=test_data_all_10_percent.class_names,\n","                      figsize=(50,50),\n","                      text_size=15,\n","                      savefig=True)"],"metadata":{"id":"CXh3VN7iZGqj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Let's keep the evaluation train going - time for a classification report\n","\n","Scikit-learn has a helpful function for acquiring many different classification metrics per class (eg. precision, recall, and F1) called classification report (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)\n","\n"],"metadata":{"id":"ZtX-iQ0225xK"}},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","\n","print(classification_report(y_true=y_labels,\n","                            y_pred=pred_classes))\n"],"metadata":{"id":"SYQLMyOb3z3M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The numbers above give a great class-by-class evaluation of our model's predictions but with so many classes, they're quite hard to understand.  \n","\n","How about we create a visualization to get a better understanding.  "],"metadata":{"id":"azoYl3434i1b"}},{"cell_type":"code","source":["# Get a dictionary of the classification report\n","classification_report_dict = classification_report(y_labels, pred_classes, output_dict=True)\n","classification_report_dict"],"metadata":{"id":"l7gejOdl4eJy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class_names[70]"],"metadata":{"id":"-ZZfqtO65LwN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's plot all our F1 scores"],"metadata":{"id":"PlFt8-O45b90"}},{"cell_type":"code","source":["# Create an empty dictionary\n","class_f1_scores = {}\n","# Loop through classification report dictionary items\n","for k, v in classification_report_dict.items():\n","  if k == \"accuracy\":  #stop once we get to accuracy key\n","    break\n","  else:\n","    # Add class names and F1 scores to new dictionary\n","    class_f1_scores[class_names[int(k)]] = v[\"f1-score\"]\n","class_f1_scores"],"metadata":{"id":"2DMUj6Qa5Ts6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Turn f1 score into dataframes for visualization\n","import pandas as pd\n","\n","f1_scores = pd.DataFrame({\"class_names\": list(class_f1_scores.keys()),\n","                          \"f1-score\": list(class_f1_scores.values())}).sort_values(\"f1-score\", ascending=False)\n","f1_scores"],"metadata":{"id":"Kmk7gqfL8G1H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","\n","fix, ax = plt.subplots(figsize=(12,25))\n","scores = ax.barh(range(len(f1_scores)), f1_scores[\"f1-score\"].values) # get f1-score values\n","ax.set_yticks(range(len(f1_scores)))\n","ax.set_yticklabels(f1_scores[\"class_names\"])\n","ax.set_xlabel(\"F1 Score\")\n","ax.set_title(\"F1 Scores for 101 different food classes (predicted by Food Vision mini)\")\n","ax.invert_yaxis() # invert the order of our y axis\n","\n","## Challenge: Add values to the end of each bar of what the actual f1-score is (hint: use the auto-label function from here)\n","ax.bar_label(scores, fmt='%.3f')\n","ax.set_xlim(right=1)  # adjust xlim to fit labels"],"metadata":{"id":"9gFG366TpzL4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred_classes"],"metadata":{"id":"fJdH5zHNwgOQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Visualizing predictions on custom images\n","How does our model go on food images not even in our food data set? (images of our own).\n","\n","To visualize our model's predictions on our own images, we'll need a function to load and preprocess images (specifically it will need to:\n","* read in a target image file path using tf.io.read_file()\n","* Turn the image into a tensor using tf.io.decode_image()\n","* resize the image tensor to be the same size as the images our model has trained on using tf.image.resize()\n","* Scale the image to get all of the pixel values between 0 and 1 if necessary"],"metadata":{"id":"MRicS6E_w7sf"}},{"cell_type":"code","source":["# Create a function to load and prepare images\n","def load_and_prep_image(filename, img_shape=(224), scale=True):\n","  \"\"\"\n","  Reads in an image from filename, turns it into a tensor and reshapes it into the specified shape (img_shape, img_shape, color_channels=3)\n","\n","  Args:\n","    filename(str): path to target images\n","    image_shape(int): height/width dimension of target image size\n","    scale (bool): scale pixel values from 0-255 to 0-1 or not\n","\n","  Returns:\n","    Image tensor of shape (image_shape, image_shape, 3)\n","  \"\"\"\n","  # Read in the image\n","  img = tf.io.read_file(filename)\n","\n","  # Decode image into tensor\n","  img = tf.io.decode_image(img, channels=3)\n","\n","  # Resize the image\n","  img = tf.image.resize(img, [img_shape, img_shape])\n","\n","  # Scale? Yes / No\n","  if scale:\n","    # rescale the image (get all values between 0 and 1)\n","    return (img/255.)\n","  else:\n","    return img  # don't need to rescale images for EfficientNet models in TensorFlow"],"metadata":{"id":"mZxg4b5LxrS-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now we've got a function to load and prepare target images, let's now write some code to visualize images, their target label, and our model's predictions.\n","\n","Specifically, we'll write some code to:\n","1. Load a few random images from the test dataset\n","2. Make predictions on the loaded images\n","3. Plot the original images along with the model's predictions, prediction probability and truth label\n"],"metadata":{"id":"X-9jmiL500ZF"}},{"cell_type":"code","source":["# Make preds on a series of random images\n","import os\n","import random\n","\n","plt.figure(figsize=(17,10))\n","for i in range(3):\n","  # Choose a random image from a random class\n","  class_name = random.choice(class_names)\n","  filename = random.choice(os.listdir(test_dir + \"/\" + class_name))\n","  filepath = test_dir + class_name + \"/\" + filename\n","  print(filepath)\n","  print(filename)\n","\n","  # Load the image and make predictions\n","  img = load_and_prep_image(filepath, scale=False)\n","  #print(img.shape)\n","  pred_prob = model.predict(tf.expand_dims(img, axis=0))                # get prediction probabilities array\n","  pred_class = class_names[pred_prob.argmax()]  # get highest prediction probability index and match it to class names list\n","  #print(pred_prob)\n","  #print(pred_class)\n","\n","  # Plot the images\n","  plt.subplot(1, 3, i+1)\n","  plt.imshow(img/255.)\n","  if class_name==pred_class:   # if predicted class matches truth class, make text green\n","    title_colour=\"g\"\n","  else:\n","    title_colour=\"r\"\n","  plt.title(f\"actual: {class_name}, pred: {pred_class}, prob: {pred_prob.max():.2f}\", c=title_colour)\n","  plt.axis(False)"],"metadata":{"id":"pILOxQ1k1WTi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","random.choice(class_names)"],"metadata":{"id":"4bv3zUJo13ys"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Finding the most wrong predictions\n","\n","To find out where our model is most wrong, let's write some code to find out the following:\n","1. Get all the image file paths in the test dataset using the list_files() method\n","2. Create a pandas dataframe of the image filepaths, ground truth labels, the predicted classes (from our model), max prediction probabilities.  \n","3. Use our dataframe to find all the wrong predictions (where the ground truth label doesn't match the prediction).\n","4. Sort the dataframe based on wrong predictions (have the highest prediction probability predictions at the top).\n","5. Visualize the images with the highest prediction probabilities but have the wrong prediction."],"metadata":{"id":"muB5207epXzx"}},{"cell_type":"code","source":["# 1. get image files paths\n","food_classes_101_test_paths = tf.data.Dataset.list_files(\"/content/101_food_classes_10_percent/test/*/*.jpg\", shuffle=False)\n","food_classes_101_test_paths\n"],"metadata":{"id":"mRWpGZ8Rrgzy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2. Create a pandas dataframe of the image filepaths, ground truth labels, the predicted classes (from our model), max prediction probabilities.\n","import pandas as pd\n","\n","max_preds_101_dataframe = pd.DataFrame({\"filepaths\":food_classes_101_test_paths.as_numpy_iterator(),\n","                                        \"y_true\":y_labels,\n","                                        \"y_pred\":pred_classes,\n","                                        \"pred_conf\":pred_probs.max(axis=1), # get the maximum pred probability value\n","                                        \"y_true_classname\":[class_names[i] for i in y_labels],\n","                                        \"y_pred_classname\":[class_names[i] for i in pred_classes]\n","                                        })\n","max_preds_101_dataframe"],"metadata":{"id":"-jRZYZjWwGwT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_preds_101_dataframe[\"pred_correct\"] = max_preds_101_dataframe[\"y_true\"] == max_preds_101_dataframe[\"y_pred\"]\n","max_preds_101_dataframe.head()"],"metadata":{"id":"R_2-g5DaPK6G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 4. Sort our dataframe to have most wrong predictions at the top\n","top_100_wrong = max_preds_101_dataframe[max_preds_101_dataframe[\"pred_correct\"] == False].sort_values(\"pred_conf\", ascending=False)[:100]\n","top_100_wrong\n","#max_preds_101_dataframe.filepaths[top_100_wrong.index[:5]]"],"metadata":{"id":"C8MIyGEuRdNL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 5. Visualize the data that has the wrong prediction but has the highest pred probability.\n","\n","plt.figure(figsize=(17,10))\n","for i in range(10):\n","  # Choose a random image from a random class\n","  #class_name = random.choice(class_names)\n","  #filename = random.choice(os.listdir(test_dir + \"/\" + class_name))\n","  #filepath = test_dir + class_name + \"/\" + filename\n","  filepath = max_preds_101_dataframe.filepaths[top_100_wrong.index[i]]\n","  #print(filepath)\n","  #print(filename)\n","\n","  # Load the image and make predictions\n","  img = load_and_prep_image(filepath, scale=False)\n","  #print(img.shape)\n","  pred_prob = max_preds_101_dataframe.pred_conf[top_100_wrong.index[i]]                # get prediction probabilities array\n","  pred_class = max_preds_101_dataframe.y_pred_classname[top_100_wrong.index[i]]  # get highest prediction probability index and match it to class names list\n","  actual_class = max_preds_101_dataframe.y_true_classname[top_100_wrong.index[i]]\n","  #print(pred_prob)\n","  #print(pred_class)\n","\n","  # Plot the images\n","  plt.subplot(4, 3, i+1)\n","  plt.imshow(img/255.)\n","  plt.tight_layout()\n","  #if class_name==pred_class:   # if predicted class matches truth class, make text green\n","  #  title_colour=\"g\"\n","  #else:\n","  #  title_colour=\"r\"\n","  #plt.title(f\"actual: {class_name}, pred: {pred_class}, prob: {pred_prob.max():.2f}\", c=title_colour)\n","  plt.title(f\"pred conf: {pred_prob}, \\n pred class: {pred_class}, actual class: {actual_class}\")\n","  plt.axis(False)"],"metadata":{"id":"FzfJN_esT4h-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Test out our big dog model on our own custom datasets"],"metadata":{"id":"ua0h6FxWPEQA"}},{"cell_type":"code","source":["# Get custom images\n","#unzip_data(\"./custom_images_mark.zip\")\n","#custom_food_images = [\"./custom_images_mark/\" + img_path for img_path in os.listdir(\"custom_images_mark\")]\n","#custom_food_images"],"metadata":{"id":"JjS2mpLDPRiY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Make predictions on and plot custom food images\n","#for img in custom_food_images:\n","#  img = load_and_prep_image(img, scale=False) # dont need to scale for our efficientnet\n","#  pred_prob = model.predict(tf.expand_dims(img, axis=0)) # make prediction on image with shape [1, 224, 224, 4] (same shape as model was trained on)\n","#  pred_class = class_names[pred_prob.argmax()] # get the index with the highest prediction probability\n","#  # Plot the appropriate information\n","#  plt.figure()\n","#  plt.imshow(img/255.)\n","#  plt.title(f\"pred: {pred_class}, prob: {pred_prob.max():.2f}, filename:\")\n","#  plt.axis(False)"],"metadata":{"id":"vzatlMXhRYwo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!rm -rf ./custom_images_mark/.DS_Store"],"metadata":{"id":"kfXqdpQMbPvG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the model\n","model_2 = tf.keras.Model(inputs,outputs)\n","\n","# Compile the model\n","new_epochs = 10\n","\n","model_2.compile(loss=\"categorical_crossentropy\",\n","                optimizer=tf.keras.optimizers.Adam(),\n","                metrics=\"accuracy\")\n","\n","history_all_classes_10_percent_more_epochs = model_2.fit(train_data_all_10_percent,\n","                                                         batch_size=32,\n","                                                         epochs=new_epochs,\n","                                                         validation_data=test_data_all_10_percent,\n","                                                         validation_steps=int(0.15 * len(test_data_all_10_percent)),\n","                                                         callbacks=[checkpoint_callback])\n"],"metadata":{"id":"0wbLoybYnsvX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["feature_extraction_results_10_epochs = model_2.evaluate(test_data_all_10_percent)\n","feature_extraction_results_10_epochs"],"metadata":{"id":"2X5jVPQmrR95"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["feature_extraction_results"],"metadata":{"id":"OkdW74sjsOnI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_classes_10_percent_fine_tune_results"],"metadata":{"id":"lkD4MA3VtJjz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras import mixed_precision\n","\n","policy = mixed_precision.Policy('mixed_float16')\n","mixed_precision.set_global_policy(policy)\n","\n","print(\"Compute dtype: %s\" % policy.compute_dtype)\n","print(\"Variable dtype: %s\" % policy.variable_dtype)"],"metadata":{"id":"V3ELdV7hu_5O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create data augmentation layer to incorporate it right into our model\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers.experimental import preprocessing\n","from tensorflow.keras.models import Sequential\n","\n","# Setup data augmentation\n","data_augmentation_mixed = Sequential([\n","    preprocessing.RandomFlip(\"horizontal\"),\n","    preprocessing.RandomRotation(0.2),\n","    preprocessing.RandomHeight(0.2),\n","    preprocessing.RandomWidth(0.2),\n","    preprocessing.RandomZoom(0.2),\n","    #preprocessing.Rescale(1/255.), #rescale inputs of images to between 0 and 1, required for models like ResNet50\n","], name=\"data_augmentation_mixed\")\n","\n","print(data_augmentation_mixed.dtype_policy)"],"metadata":{"id":"J_POdpawxgz9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Setup the base model and freeze its layers (this will extract features)\n","base_model_mixed=tf.keras.applications.EfficientNetB0(include_top=False)\n","base_model_mixed.trainable = False\n","\n","#Setup model architecture with trainable top layers\n","inputs_mixed = layers.Input(shape=(224,224,3), name=\"input_layer\")\n","x_mixed = data_augmentation(inputs_mixed) # augment images (only happens during training phase)\n","x_mixed = base_model(x_mixed, training=False) # This will put the base model into inference mode so weights which need to stay frozen stay frozen\n","x_mixed = layers.GlobalAveragePooling2D(name=\"global_avg_pool_layer\")(x_mixed)\n","outputs_mixed = layers.Dense(len(train_data_all_10_percent.class_names), activation=\"softmax\", name=\"output_layer\", dtype=\"float32\")(x_mixed)\n","model_mixed_precision = tf.keras.Model(inputs_mixed, outputs_mixed)\n","print(\"Outputs dtype: %s\" % outputs_mixed.dtype)"],"metadata":{"id":"Oz_yfeqgxoyH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Recreate the first model with mixed-precision turned on\n","\n","# Define the model\n","model_mixed_precision = tf.keras.Model(inputs,outputs)\n","\n","# Compile the model\n","epochs = 5\n","\n","model_mixed_precision.compile(loss=\"categorical_crossentropy\",\n","                optimizer=tf.keras.optimizers.Adam(),\n","                metrics=\"accuracy\",)\n","\n","history_all_classes_10_percent_mixed_precision = model_mixed_precision.fit(train_data_all_10_percent,\n","                                                         batch_size=32,\n","                                                         epochs=epochs,\n","                                                         validation_data=test_data_all_10_percent,\n","                                                         validation_steps=int(0.15 * len(test_data_all_10_percent)),\n","                                                         callbacks=[checkpoint_callback])"],"metadata":{"id":"UJIIVzzhtecJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results_mixed_precision = model_mixed_precision.evaluate(test_data_all_10_percent)\n","results_mixed_precision"],"metadata":{"id":"xAdp8oTP2QQN"},"execution_count":null,"outputs":[]}]}