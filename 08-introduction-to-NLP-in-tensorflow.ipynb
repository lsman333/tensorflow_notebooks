{"cells":[{"cell_type":"code","source":["#We need to install tf version 2.15 for compatibility with this notebook (written in March 2024).\n","!pip uninstall tensorflow\n","!pip install tensorflow==2.15.0\n","!tensorflow --version"],"metadata":{"id":"QVITFDvZIim9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gp6aiA4w3ASg"},"source":["# Introduction to NLP fundamentals in Tensorflow\n","\n","NLP has the goal of deriving information out of natural language (could be sequences text or speech)\n","\n","Another common term for NLP problems is sequence to sequence (seq2seq)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":205,"status":"ok","timestamp":1730161884902,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"QZfQXMvw3atp","outputId":"5628ed59-b8de-4fc3-84ad-42d472808a84"},"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: nvidia-smi: command not found\n"]}],"source":["!nvidia-smi -L"]},{"cell_type":"markdown","metadata":{"id":"4SLWrZei3i3e"},"source":["## Get helper functions\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":233,"status":"ok","timestamp":1730161886306,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"6wQC6BON3z7V","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e720a1ca-1466-4f49-fa57-7409a904a6e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-10-29 00:31:25--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 10246 (10K) [text/plain]\n","Saving to: ‘helper_functions.py’\n","\n","helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n","\n","2024-10-29 00:31:25 (63.0 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n","\n"]}],"source":["!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0pRCTT6L32ne"},"outputs":[],"source":["# Import a series of helper functions for the notebook\n","from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys, make_confusion_matrix"]},{"cell_type":"markdown","metadata":{"id":"iuYMsBc_4IlT"},"source":["## Get a text dataset\n","\n","The dataset we are going to be using is Kaggle's introduction to NLP dataset.  (Text samples of tweets labelled as disaster or not disaster).  \n","\n","See the original source here: https://www.kaggle.com/c/nlp-getting-started/\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":169,"status":"ok","timestamp":1730161903488,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"UtEwvcUU4tO7","outputId":"1f074463-7cd3-43e5-de51-66efc6277af0"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-10-29 00:31:43--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.65.123, 172.217.15.251, 172.217.164.27, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.65.123|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 607343 (593K) [application/zip]\n","Saving to: ‘nlp_getting_started.zip’\n","\n","\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.008s  \n","\n","2024-10-29 00:31:43 (75.8 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n","\n"]}],"source":["!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n","\n","unzip_data(\"nlp_getting_started.zip\")"]},{"cell_type":"markdown","metadata":{"id":"JCVcSG4nHoG-"},"source":["## Visualizing a text dataset\n","\n","To visualize our text samples, we first have to read them in.  https://realpython.com/read-write-files-python/\n","\n","One way to do so would be to use Python, but I prefer to get visual straight away.\n","\n","Another way is to use Pandas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nHcb8b2AIceH"},"outputs":[],"source":["import pandas as pd\n","train_df = pd.read_csv(\"train.csv\")\n","test_df = pd.read_csv(\"test.csv\")\n","#dads_df = pd.read_csv(\"tweets.csv\", header=None)\n","#train_df.head()\n","#test_df.head()\n","#dads_list = dads_df.values.tolist()\n","#dads_list\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1730161903661,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"dBuUzriFJAEm","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b8ffd311-ea58-4dc0-c202-225bcd72e5f7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["('Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all',\n"," 'Just happened a terrible car crash')"]},"metadata":{},"execution_count":6}],"source":["train_df[\"text\"][0],test_df[\"text\"][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":244,"status":"ok","timestamp":1730161903905,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"px3XbeCyJNdr","colab":{"base_uri":"https://localhost:8080/","height":206},"outputId":"cbefb8f3-1684-473e-9277-3d4828e939ae"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["        id     keyword                      location  \\\n","2406  8051    refugees                           NaN   \n","134    425  apocalypse  Currently Somewhere On Earth   \n","411   1330  blown%20up                   Scout Team    \n","203    663      attack                           NaN   \n","889   2930      danger                        Leeds    \n","\n","                                                   text  \n","2406  Refugees as citizens - The Hindu http://t.co/G...  \n","134   @5SOStag honestly he could say an apocalypse i...  \n","411   If you bored as shit don't nobody fuck wit you...  \n","203   @RealTwanBrown Yesterday I Had A Heat Attack ?...  \n","889   The Devil Wears Prada is still one of my favou...  "],"text/html":["\n","  <div id=\"df-c5cd5cb8-47d4-4263-be10-ef530ef07508\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>keyword</th>\n","      <th>location</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2406</th>\n","      <td>8051</td>\n","      <td>refugees</td>\n","      <td>NaN</td>\n","      <td>Refugees as citizens - The Hindu http://t.co/G...</td>\n","    </tr>\n","    <tr>\n","      <th>134</th>\n","      <td>425</td>\n","      <td>apocalypse</td>\n","      <td>Currently Somewhere On Earth</td>\n","      <td>@5SOStag honestly he could say an apocalypse i...</td>\n","    </tr>\n","    <tr>\n","      <th>411</th>\n","      <td>1330</td>\n","      <td>blown%20up</td>\n","      <td>Scout Team</td>\n","      <td>If you bored as shit don't nobody fuck wit you...</td>\n","    </tr>\n","    <tr>\n","      <th>203</th>\n","      <td>663</td>\n","      <td>attack</td>\n","      <td>NaN</td>\n","      <td>@RealTwanBrown Yesterday I Had A Heat Attack ?...</td>\n","    </tr>\n","    <tr>\n","      <th>889</th>\n","      <td>2930</td>\n","      <td>danger</td>\n","      <td>Leeds</td>\n","      <td>The Devil Wears Prada is still one of my favou...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5cd5cb8-47d4-4263-be10-ef530ef07508')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-c5cd5cb8-47d4-4263-be10-ef530ef07508 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-c5cd5cb8-47d4-4263-be10-ef530ef07508');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-c8e1b570-1cfe-4afc-85e7-d5c1c19ddd88\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c8e1b570-1cfe-4afc-85e7-d5c1c19ddd88')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-c8e1b570-1cfe-4afc-85e7-d5c1c19ddd88 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"test_df_shuffled","summary":"{\n  \"name\": \"test_df_shuffled\",\n  \"rows\": 3263,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3146,\n        \"min\": 0,\n        \"max\": 10875,\n        \"num_unique_values\": 3263,\n        \"samples\": [\n          5994,\n          1581,\n          4460\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keyword\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 221,\n        \"samples\": [\n          \"suicide%20bomber\",\n          \"injury\",\n          \"ruin\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1602,\n        \"samples\": [\n          \"????\",\n          \"Italia\",\n          \"lagos , Usa\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3243,\n        \"samples\": [\n          \"Tonight It's Going To Be Mayhem @ #4PlayThursdays. Everybody Free w/ Text. 1716 I ST NW (18+) http://t.co/omYWCLpGEf\",\n          \"Sammy is here in this war zone. Jamal spoke to me on the phone. Now my wife is next to speak to me ...what else can&gt; http://t.co/2CppfprxoG\",\n          \"Permutable site conspiracy up-to-the-minute upheaval: QWkD\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":7}],"source":["# Shuffle training dataframe\n","train_df_shuffled = train_df.sample(frac=1, random_state=42)\n","train_df_shuffled.head()\n","\n","# Shuffle test dataframe\n","test_df_shuffled = test_df.sample(frac=1, random_state=42)\n","test_df_shuffled.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":245,"status":"ok","timestamp":1730161904149,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"dYHpUxkAJkRn","colab":{"base_uri":"https://localhost:8080/","height":206},"outputId":"13aa4c18-3389-4142-9dbf-5b39c3c66f74"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   id keyword location                                               text\n","0   0     NaN      NaN                 Just happened a terrible car crash\n","1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n","2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n","3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n","4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"],"text/html":["\n","  <div id=\"df-6c85c14c-803b-44e3-9553-79dfb724bb2b\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>keyword</th>\n","      <th>location</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Just happened a terrible car crash</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Heard about #earthquake is different cities, s...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>there is a forest fire at spot pond, geese are...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Apocalypse lighting. #Spokane #wildfires</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c85c14c-803b-44e3-9553-79dfb724bb2b')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-6c85c14c-803b-44e3-9553-79dfb724bb2b button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-6c85c14c-803b-44e3-9553-79dfb724bb2b');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-7dd5260e-3f39-4c6f-9907-464786cbf1fc\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7dd5260e-3f39-4c6f-9907-464786cbf1fc')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-7dd5260e-3f39-4c6f-9907-464786cbf1fc button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"test_df","summary":"{\n  \"name\": \"test_df\",\n  \"rows\": 3263,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3146,\n        \"min\": 0,\n        \"max\": 10875,\n        \"num_unique_values\": 3263,\n        \"samples\": [\n          8051,\n          425,\n          1330\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keyword\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 221,\n        \"samples\": [\n          \"injury\",\n          \"nuclear%20reactor\",\n          \"engulfed\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1602,\n        \"samples\": [\n          \"UAE\",\n          \"Tokio / Tokyo\",\n          \"Texas\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3243,\n        \"samples\": [\n          \"Latest: USA: Huge sinkhole swallows up Brooklyn intersection http://t.co/vspKHg3nZy\",\n          \"I liked a @YouTube video http://t.co/a5YTAw9Vih S.O.S. Rona Guide - The Red Whirlwind\",\n          \"HitchBot travels Europe and greeted with open arms. Gets destroyed after two weeks in america. There's a lesson to be learned here.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":8}],"source":["# What does the test dataframe look like?\n","test_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1730161904149,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"vTlEKJzQJt4L","colab":{"base_uri":"https://localhost:8080/","height":178},"outputId":"1ae0f407-8321-48c2-dd8d-6cc3c62399bb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["target\n","0    4342\n","1    3271\n","Name: count, dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>target</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4342</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3271</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":9}],"source":["# How many examples of each class?\n","train_df.target.value_counts()\n","#test_df.text.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1730161904149,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"_2z_lHDcKX0G","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a87a65a7-d236-4c85-b09c-1262fa66f915"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(7613, 3263)"]},"metadata":{},"execution_count":10}],"source":["# How many total samples?\n","len(train_df), len(test_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1730161904149,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"bn4NFivuKfHG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8b9aaac0-34d5-4115-9b14-53006d2ca04d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Target: 0 (not real disaster)\n","Text:\n","Downtown Emergency Service Center is hiring a #Chemical #Dependency Counselor or Intern apply now! #Seattle #jobs http://t.co/SKQPWSNOin\n","\n","---\n","\n","Target: 1 (real disaster)\n","Text:\n","Watch This Airport Get Swallowed Up By A Sandstorm In Under A Minute http://t.co/mkWyvM3i8r\n","\n","---\n","\n","Target: 0 (not real disaster)\n","Text:\n","I don't doubt it. But it was his implicit statement in doing it that makes me want him flattened by a bus. https://t.co/5hlJUcxI0S\n","\n","---\n","\n","Target: 0 (not real disaster)\n","Text:\n","Wow. #FIFA16 has Pre Season Tournaments in Career Mode. Bloody hell evacuate the building #whocares\n","\n","---\n","\n","Target: 0 (not real disaster)\n","Text:\n","@RVacchianoNYDN The only surprise is that they aren't ALL injured.\n","\n","---\n","\n"]}],"source":["# Let's visualize some random training examples\n","import random\n","random_index = random.randint(0, len(train_df)-5) # create random indexes not higher than the total number of samples\n","\n","for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n","  _, text, target = row\n","  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n","  print(f\"Text:\\n{text}\\n\")\n","  print(f\"---\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":291,"status":"ok","timestamp":1730161904438,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"geUGp2cedoeC","colab":{"base_uri":"https://localhost:8080/"},"outputId":"cad2b8a5-d3af-4c6a-8fa5-391e7bace755"},"outputs":[{"output_type":"stream","name":"stdout","text":["Text:\n","@EddieTrunk Blizzard of Ozz\n","\n","---\n","\n","Text:\n","hijack\n","\n","---\n","\n","Text:\n","Suicide bomber kills 15 in Saudi security site mosque - Reuters http://t.co/KCObrZBVDs http://t.co/y62HSFVIAQ\n","\n","---\n","\n","Text:\n","True strength is forgiveness. Love the most powerful weapon. .@vickysuewrites' Broken Circle'\n","\n","#giveaway #boyxboy http://t.co/Zgc3EsLNPS\n","\n","---\n","\n","Text:\n","@justgetawayx everything will turn out fine!! I went to lp/om&amp;m alone and survived it and so can you\n","\n","---\n","\n"]}],"source":["# Let's visualize some random test examples (TEST sentences)#\n","import random\n","random_index = random.randint(0, len(test_df)-5)\n","\n","for row in test_df_shuffled[[\"location\", \"text\"]][random_index:random_index+5].itertuples():\n","  _, location, text = row\n","  print(f\"Text:\\n{text}\\n\")\n","  print(f\"---\\n\")"]},{"cell_type":"markdown","metadata":{"id":"GVX98G91UELd"},"source":["### Split data into training and validation sets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X8adekM9UVrD"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yK8Yf_K8UrUl"},"outputs":[],"source":["# Use train_test_split to split the data into training and validation sets\n","train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n","                                                                            train_df_shuffled[\"target\"].to_numpy(),\n","                                                                            test_size=0.1, # use 10% of training data for validation split\n","                                                                            random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MaYNdLYFftFt"},"outputs":[],"source":["# predict on the TEST sentences\n","#my_prediction_probs = model_6.predict(test_df_shuffled[\"text\"].to_numpy())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kcd0E8KggmnW"},"outputs":[],"source":["#my_prediction_probs"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1730161904639,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"sZfKTG1bVgS0","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c4bab72e-b806-410a-aaf3-d95974d1479c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(6851, 6851, 762, 762)"]},"metadata":{},"execution_count":17}],"source":["# Check the lengths\n","len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1730161904639,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"2QreLXdLVskM","colab":{"base_uri":"https://localhost:8080/"},"outputId":"820c9ff7-9a4e-4491-9ee9-8d81051bb899"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n","        'Imagine getting flattened by Kurt Zouma',\n","        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n","        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n","        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n","        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n","        'destroy the free fandom honestly',\n","        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n","        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n","        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n","       dtype=object),\n"," array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"]},"metadata":{},"execution_count":18}],"source":["# Check the first 10 samples\n","train_sentences[:10], train_labels[:10]"]},{"cell_type":"markdown","metadata":{"id":"h481sV71YBmK"},"source":["## Converting text into numbers\n","\n","When dealing with a text problem, one of the first things you will have to do before you can build a model, is to convert your text into numbers.  There are a few ways to do this, namely:\n","* Tokenization: direct mapping of token (a token could be a word or character) to a number\n","* Embedding: create an embedding of feature vectors for each token (the size of the feature vector can be defined and this embedding can be learned)"]},{"cell_type":"markdown","metadata":{"id":"FRtOUzjWBX2I"},"source":["### Text vectorization (tokenization)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":185,"status":"ok","timestamp":1730161904822,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"rcxFdVrlBdTz","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6a11e159-9d12-4e53-8898-16bc6430a3b9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['@mogacola @zamtriossu i screamed after hitting tweet',\n","       'Imagine getting flattened by Kurt Zouma',\n","       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n","       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n","       'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n","      dtype=object)"]},"metadata":{},"execution_count":19}],"source":["train_sentences[:5]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H3U3TOhgBkfU"},"outputs":[],"source":["import tensorflow as tf\n","from tf_keras.layers.experimental.preprocessing import TextVectorization\n","\n","# Use the default TextVectorization parameters\n","text_vectorizer = TextVectorization(max_tokens=10000,  # how many words in the vocabulary? (automatically add <OOV>)\n","                                    standardize=\"lower_and_strip_punctuation\",\n","                                    split=\"whitespace\",\n","                                    ngrams=None, # create groups of n-words\n","                                    output_mode=\"int\", # how to map tokens to number\n","                                    output_sequence_length=None,  # how long do you want your sequences to be?\n","                                    pad_to_max_tokens=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1730161909991,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"LqoHv2m2GSRj","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f932829b-7b64-431e-aa91-e601a5c9a334"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["7"]},"metadata":{},"execution_count":21}],"source":["len(train_sentences[0].split())"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1730161909991,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"0CIn1HGjGEEt","colab":{"base_uri":"https://localhost:8080/"},"outputId":"70e0407e-9e9b-45c4-910e-6a0807fa1193"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["15"]},"metadata":{},"execution_count":22}],"source":["# Find the average number of tokens (words) in the training tweets\n","round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E_C8FIeuHX44"},"outputs":[],"source":["# Setup text vectorization variables\n","max_vocab_length = 10000 # max number of words to have in our vocabulary\n","max_length = 15 # max length our sequences will be (eg. how many words from a Tweet does our model see?)\n","\n","text_vectorizer = TextVectorization(max_tokens = max_vocab_length,\n","                                    output_mode=\"int\",\n","                                    output_sequence_length=max_length)\n","\n","# Create text vectorizer for TEST data set\n","text_vectorizer_test = TextVectorization(max_tokens = max_vocab_length,\n","                                    output_mode=\"int\",\n","                                    output_sequence_length=max_length)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r0HSLqrZ2CWX"},"outputs":[],"source":["# Fit the text vectorizer to the training text\n","text_vectorizer.adapt(train_sentences)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Wr-FQ5hhEiM"},"outputs":[],"source":["# Fit the text vectorizer to the TEST text\n","#text_vectorizer_test.adapt(test_df_shuffled[\"text\"].to_numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":252,"status":"ok","timestamp":1730161912356,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"Jd3WxvZx2Ur5","colab":{"base_uri":"https://localhost:8080/"},"outputId":"424431ed-1543-4417-99ff-3458b7d57c0e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n","array([[  19,    9,    3, 8839,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1]])>"]},"metadata":{},"execution_count":26}],"source":["# Create a sample sentence and tokenize it\n","sample_sentence = \"This is a sample sjdfhakdjfasf sadfj asdkfjh askdjf sakjfh aks asdf asdf asdf asdf safdsadfsadf \"\n","text_vectorizer([sample_sentence])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1730161912356,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"8jYvy5MQ4P-M","colab":{"base_uri":"https://localhost:8080/"},"outputId":"00447de5-d724-4c74-e621-5fce3cc0f61c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original text: Ted Cruz fires back at Jeb &amp; Bush: ÛÏWe lose because of Republicans like Jeb &amp; Mitt.Û [Video] -  http://t.co/KCofF6BmiE\n","Vectorized version: [[2264 1534  109   88   17 1828   35  657 3227 1505  152    6 2004   25\n","  1828]]\n"]}],"source":["# Choose a random sentence from the training dataset and tokenize it\n","random_sentence = random.choice(train_sentences)\n","print(f\"Original text: {random_sentence}\\n\\\n","Vectorized version: {text_vectorizer([random_sentence])}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gJ9T7dRshk99"},"outputs":[],"source":["# Choose a random sentence from the TEST dataset and tokenize it\n","#random_sentence_test = random.choice(test_df_shuffled[\"text\"].to_numpy())\n","#print(f\"Original text: {random_sentence_test}\\n\\\n","#Vectorized version: {text_vectorizer_test([random_sentence_test])}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":209,"status":"ok","timestamp":1730161912564,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"AIxuKfw46d4w","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8568d3ff-d436-47de-9f17-cedfa6729bc6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of words in vocab: 10000\n","Most common 5 words: ['', '[UNK]', 'the', 'a', 'in']\n","Least common 5 words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"]}],"source":["# Get the unique words in the vocabulary\n","words_in_vocab = text_vectorizer.get_vocabulary() # Get all of the unique words in our training data\n","top_5_words = words_in_vocab[:5] # get the most common words\n","bottom_5_words = words_in_vocab[-5:] # get the least common words\n","print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n","print(f\"Most common 5 words: {top_5_words}\")\n","print(f\"Least common 5 words: {bottom_5_words}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1730161912564,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"I6ysN03rq5Tb","colab":{"base_uri":"https://localhost:8080/","height":458},"outputId":"2b94ce11-f199-4800-9d77-2eb7d44916fe"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0                      Just happened a terrible car crash\n","1       Heard about #earthquake is different cities, s...\n","2       there is a forest fire at spot pond, geese are...\n","3                Apocalypse lighting. #Spokane #wildfires\n","4           Typhoon Soudelor kills 28 in China and Taiwan\n","                              ...                        \n","3258    EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...\n","3259    Storm in RI worse than last hurricane. My city...\n","3260    Green Line derailment in Chicago http://t.co/U...\n","3261    MEG issues Hazardous Weather Outlook (HWO) htt...\n","3262    #CityofCalgary has activated its Municipal Eme...\n","Name: text, Length: 3263, dtype: object"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Just happened a terrible car crash</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Heard about #earthquake is different cities, s...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>there is a forest fire at spot pond, geese are...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Apocalypse lighting. #Spokane #wildfires</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3258</th>\n","      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n","    </tr>\n","    <tr>\n","      <th>3259</th>\n","      <td>Storm in RI worse than last hurricane. My city...</td>\n","    </tr>\n","    <tr>\n","      <th>3260</th>\n","      <td>Green Line derailment in Chicago http://t.co/U...</td>\n","    </tr>\n","    <tr>\n","      <th>3261</th>\n","      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n","    </tr>\n","    <tr>\n","      <th>3262</th>\n","      <td>#CityofCalgary has activated its Municipal Eme...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3263 rows × 1 columns</p>\n","</div><br><label><b>dtype:</b> object</label>"]},"metadata":{},"execution_count":30}],"source":["sentences = test_df[\"text\"]\n","sentences"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1730161912564,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"zgWyzOYKibDA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d86ad544-a3e9-469f-c5ef-139cf4ac088a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of words in vocab: 2\n","Most common 5 words ['', '[UNK]']\n","Least common 5 words: ['', '[UNK]']\n"]}],"source":["# Get the unique words in the vocabulary (TEST)\n","words_in_vocab_test = text_vectorizer_test.get_vocabulary()\n","top_5_words_test = words_in_vocab_test[:5]\n","bottom_5_words_test = words_in_vocab_test[-5:]\n","print(f\"Number of words in vocab: {len(words_in_vocab_test)}\")\n","print(f\"Most common 5 words {top_5_words_test}\")\n","print(f\"Least common 5 words: {bottom_5_words_test}\")"]},{"cell_type":"markdown","metadata":{"id":"E-9N8dBQ85ye"},"source":["### Creating an embedding using an embedding layer\n","\n","To make our embedding, we're going to use TensorFlow's embedding layer:\n","https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n","\n","The parameters we care most about for our embedding layer:\n","* `input_dim` = the size of our vocabulary\n","* `output_dim` = the size of the output embedding vector, for example, a value of 100 would mean each token gets represented by a vector 100 long\n","* `input_length` = length of the sequences being passed to the embedding layer"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1730161912564,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"NwIguier-EOD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"73331825-8fe2-4054-8996-5061dd54fbd9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf_keras.src.layers.core.embedding.Embedding at 0x7c5944447520>"]},"metadata":{},"execution_count":32}],"source":["from tf_keras import layers\n","\n","embedding = layers.Embedding(input_dim=max_vocab_length,  # set input shape\n","                             output_dim=128,    # output shape\n","                             input_length=max_length)    #how long is each input\n","\n","embedding"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":240,"status":"ok","timestamp":1730161912802,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"VzQ-Ph-i-nSy","colab":{"base_uri":"https://localhost:8080/"},"outputId":"eddb8fd0-8d04-4a2b-cbf9-80877d9d587d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original text: @SirTitan45  Mega mood swing on a 24 hr schedule. Isn't that how structural failure occurs?\n","      Embedded version:\n"]},{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n","array([[[ 0.0035265 , -0.00192551, -0.00049866, ..., -0.03761262,\n","         -0.00232654,  0.00720401],\n","        [-0.01537702, -0.0029817 ,  0.00035368, ..., -0.01856076,\n","         -0.02273378,  0.03584871],\n","        [-0.01172631, -0.01688895,  0.04851237, ..., -0.0493596 ,\n","          0.03826752, -0.02759098],\n","        ...,\n","        [-0.03915339, -0.00063073,  0.00277761, ...,  0.04219371,\n","         -0.0355489 ,  0.0086624 ],\n","        [ 0.02828783, -0.02011579,  0.01987657, ..., -0.03309675,\n","          0.01295484, -0.02917149],\n","        [-0.04228786,  0.00597602,  0.04027947, ...,  0.00243164,\n","          0.03805712, -0.02725112]]], dtype=float32)>"]},"metadata":{},"execution_count":33}],"source":["# Get a random sentence from the training set\n","random_sentence = random.choice(train_sentences)\n","print(f\"Original text: {random_sentence}\\n\\\n","      Embedded version:\")\n","\n","# Embed the random sentence (turn it into dense vectors of fixed size)\n","sample_embed = embedding(text_vectorizer([random_sentence]))\n","sample_embed"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":187,"status":"ok","timestamp":1730161912988,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"N8l2KpN0rBhw","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e0eb4a0a-94c2-4e5e-d717-49ec6e2be16b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n"," array([ 0.0035265 , -0.00192551, -0.00049866,  0.02369261, -0.04725368,\n","         0.03907185, -0.03496747,  0.00751869,  0.024002  , -0.04037524,\n","        -0.01281999, -0.01699594,  0.00696826,  0.00430919, -0.04398051,\n","         0.01848395,  0.04423733, -0.04345018,  0.00499805, -0.00670303,\n","         0.0337593 ,  0.04039404,  0.00048391,  0.01323633,  0.01760931,\n","         0.03256628,  0.04968696, -0.02814697, -0.00420803,  0.02528762,\n","         0.01410453, -0.02271535,  0.03196447,  0.03234461, -0.04269974,\n","        -0.03544481,  0.04603864,  0.03866308, -0.01587731,  0.04028252,\n","         0.00488121,  0.0450185 ,  0.00535149,  0.01476162, -0.02452957,\n","         0.03055633,  0.01507142, -0.00794442, -0.02879271,  0.00304198,\n","         0.04369305, -0.00062605,  0.0189379 , -0.04961009,  0.01405681,\n","        -0.01739249,  0.04697261, -0.04259024,  0.04902686, -0.02689931,\n","        -0.01898794,  0.01933109,  0.00152041, -0.04510957, -0.04238583,\n","        -0.0205606 , -0.02473241, -0.04017991, -0.04555035, -0.00187717,\n","        -0.01128447,  0.0329578 , -0.02304683, -0.0354914 ,  0.03756938,\n","        -0.00266271,  0.04772053,  0.03549058,  0.03510468,  0.0360204 ,\n","         0.00222087, -0.04117655,  0.04038056, -0.0366241 , -0.04927713,\n","        -0.02511052,  0.01218134,  0.04238781, -0.00415004,  0.01690814,\n","         0.04195065,  0.00170702,  0.01237992, -0.03771143,  0.01909763,\n","         0.03988457,  0.02796458,  0.02283717, -0.01815127,  0.03158054,\n","         0.01516923, -0.03748722, -0.0401377 ,  0.04890926,  0.01494533,\n","         0.0064266 ,  0.01731848,  0.02388701,  0.0365585 , -0.00164044,\n","        -0.03971403,  0.04916782,  0.00684803,  0.03874493,  0.00929372,\n","        -0.02068312, -0.0430584 ,  0.0186144 ,  0.0095998 ,  0.04292883,\n","        -0.03793124, -0.03956335, -0.00404201, -0.03103311, -0.01854138,\n","        -0.03761262, -0.00232654,  0.00720401], dtype=float32)>,\n"," TensorShape([128]),\n"," '@')"]},"metadata":{},"execution_count":34}],"source":["# Check out a single token's embedding\n","sample_embed[0][0], sample_embed[0][0].shape, random_sentence[0]"]},{"cell_type":"markdown","metadata":{"id":"kHrdd59NtPPT"},"source":["## Modeling a text dataset (running a series of experiments)\n","\n","Now we've got a way to turn our text sequences into numbers, it's time to start building a series of modeling experiments.  We'll start with a baseline and move on from there.\n","\n","* Model 0: Naive Bayes (baseline) - this is from Scikit ML map: https://scikit-learn.org/stable/modules/naive_bayes.html https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n","* Model 1: Feed-forward neural network (dense model)\n","* Model 2: LSTN model (RNN)\n","* Model 3: GRU model (RNN)\n","* Model 4: Bidirectional-LSTM model (RNN)\n","* Model 5: 1D Convolutional Neural Network (CNN)\n","* Model 6: TensorFlow Hub Pre-trained Feature Extractor (using transfer learning for NLP)\n","* Model 7: Same as model 6 with 10% of the training data.\n","\n","How are we going to approach all of these?\n","\n","Use the standard steps in modelling with TensorFlow:\n","\n","* Create a model\n","* Build a model\n","* Fit model\n","* Evaluate\n","\n"]},{"cell_type":"markdown","metadata":{"id":"wRNkr6525qrG"},"source":["### Model 0: Getting a baseline\n","\n","As with all machine learning modelling experiments, it's important to create a baseline model so you've got a benchmark for future experiments to build upon.\n","\n","To create our baseline we'll use sklearn's multinomial naive bais using the tf-idf formula to convert our words to numbers.\n","\n","> 🔑 Note: it's common practice to use non-DL algorithms as a baseline because of their speed and then later using DL to improve upon them."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":520,"status":"ok","timestamp":1730161913507,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"H87p49QV6KLp","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0c815323-0800-4204-a17d-f786061566b4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(6851, 20076)"]},"metadata":{},"execution_count":35}],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","count_vect = CountVectorizer()\n","X_train_counts = count_vect.fit_transform(train_sentences)\n","X_train_counts.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EA_tWMZuAhDV"},"outputs":[],"source":["count_vect.vocabulary_.get(u'algorithm')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1730161913507,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"DISP7BjPAslV","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3cbc0279-0a90-41c1-944a-3422ccc9fdc6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(6851, 20076)"]},"metadata":{},"execution_count":37}],"source":["from sklearn.feature_extraction.text import TfidfTransformer\n","tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_counts)\n","X_train_tf = tf_transformer.transform(X_train_counts)\n","X_train_tf.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1730161913507,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"-2GfQC_ZB0uQ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"71e2fce0-d1e0-46aa-f85e-fb228760b65f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(6851, 20076)"]},"metadata":{},"execution_count":38}],"source":["tfidf_transformer = TfidfTransformer()\n","X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n","X_train_tfidf.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":191,"status":"ok","timestamp":1730161913697,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"ZMh5YcbUDrhU","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"4bfaa13f-a9dd-4cff-ac51-189643d2bc45"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'@mogacola @zamtriossu i screamed after hitting tweet'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":39}],"source":["train_sentences[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tNNN4fysCf8X"},"outputs":[],"source":["#from sklearn.naive_bayes import MultinomialNB\n","#model_0 = MultinomialNB.fit(X=train_sentences, y=train_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":574,"status":"ok","timestamp":1730161914270,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"zIqGDdVYFhZw","colab":{"base_uri":"https://localhost:8080/","height":142},"outputId":"b1171ead-e9e6-4851-c5b0-3af1412d7dd9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"],"text/html":["<style>#sk-container-id-1 {\n","  /* Definition of color scheme common for light and dark mode */\n","  --sklearn-color-text: black;\n","  --sklearn-color-line: gray;\n","  /* Definition of color scheme for unfitted estimators */\n","  --sklearn-color-unfitted-level-0: #fff5e6;\n","  --sklearn-color-unfitted-level-1: #f6e4d2;\n","  --sklearn-color-unfitted-level-2: #ffe0b3;\n","  --sklearn-color-unfitted-level-3: chocolate;\n","  /* Definition of color scheme for fitted estimators */\n","  --sklearn-color-fitted-level-0: #f0f8ff;\n","  --sklearn-color-fitted-level-1: #d4ebff;\n","  --sklearn-color-fitted-level-2: #b3dbfd;\n","  --sklearn-color-fitted-level-3: cornflowerblue;\n","\n","  /* Specific color for light theme */\n","  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n","  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-icon: #696969;\n","\n","  @media (prefers-color-scheme: dark) {\n","    /* Redefinition of color scheme for dark theme */\n","    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n","    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-icon: #878787;\n","  }\n","}\n","\n","#sk-container-id-1 {\n","  color: var(--sklearn-color-text);\n","}\n","\n","#sk-container-id-1 pre {\n","  padding: 0;\n","}\n","\n","#sk-container-id-1 input.sk-hidden--visually {\n","  border: 0;\n","  clip: rect(1px 1px 1px 1px);\n","  clip: rect(1px, 1px, 1px, 1px);\n","  height: 1px;\n","  margin: -1px;\n","  overflow: hidden;\n","  padding: 0;\n","  position: absolute;\n","  width: 1px;\n","}\n","\n","#sk-container-id-1 div.sk-dashed-wrapped {\n","  border: 1px dashed var(--sklearn-color-line);\n","  margin: 0 0.4em 0.5em 0.4em;\n","  box-sizing: border-box;\n","  padding-bottom: 0.4em;\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","#sk-container-id-1 div.sk-container {\n","  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n","     but bootstrap.min.css set `[hidden] { display: none !important; }`\n","     so we also need the `!important` here to be able to override the\n","     default hidden behavior on the sphinx rendered scikit-learn.org.\n","     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n","  display: inline-block !important;\n","  position: relative;\n","}\n","\n","#sk-container-id-1 div.sk-text-repr-fallback {\n","  display: none;\n","}\n","\n","div.sk-parallel-item,\n","div.sk-serial,\n","div.sk-item {\n","  /* draw centered vertical line to link estimators */\n","  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n","  background-size: 2px 100%;\n","  background-repeat: no-repeat;\n","  background-position: center center;\n","}\n","\n","/* Parallel-specific style estimator block */\n","\n","#sk-container-id-1 div.sk-parallel-item::after {\n","  content: \"\";\n","  width: 100%;\n","  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n","  flex-grow: 1;\n","}\n","\n","#sk-container-id-1 div.sk-parallel {\n","  display: flex;\n","  align-items: stretch;\n","  justify-content: center;\n","  background-color: var(--sklearn-color-background);\n","  position: relative;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item {\n","  display: flex;\n","  flex-direction: column;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item:first-child::after {\n","  align-self: flex-end;\n","  width: 50%;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item:last-child::after {\n","  align-self: flex-start;\n","  width: 50%;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item:only-child::after {\n","  width: 0;\n","}\n","\n","/* Serial-specific style estimator block */\n","\n","#sk-container-id-1 div.sk-serial {\n","  display: flex;\n","  flex-direction: column;\n","  align-items: center;\n","  background-color: var(--sklearn-color-background);\n","  padding-right: 1em;\n","  padding-left: 1em;\n","}\n","\n","\n","/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n","clickable and can be expanded/collapsed.\n","- Pipeline and ColumnTransformer use this feature and define the default style\n","- Estimators will overwrite some part of the style using the `sk-estimator` class\n","*/\n","\n","/* Pipeline and ColumnTransformer style (default) */\n","\n","#sk-container-id-1 div.sk-toggleable {\n","  /* Default theme specific background. It is overwritten whether we have a\n","  specific estimator or a Pipeline/ColumnTransformer */\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","/* Toggleable label */\n","#sk-container-id-1 label.sk-toggleable__label {\n","  cursor: pointer;\n","  display: block;\n","  width: 100%;\n","  margin-bottom: 0;\n","  padding: 0.5em;\n","  box-sizing: border-box;\n","  text-align: center;\n","}\n","\n","#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n","  /* Arrow on the left of the label */\n","  content: \"▸\";\n","  float: left;\n","  margin-right: 0.25em;\n","  color: var(--sklearn-color-icon);\n","}\n","\n","#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n","  color: var(--sklearn-color-text);\n","}\n","\n","/* Toggleable content - dropdown */\n","\n","#sk-container-id-1 div.sk-toggleable__content {\n","  max-height: 0;\n","  max-width: 0;\n","  overflow: hidden;\n","  text-align: left;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-toggleable__content.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-toggleable__content pre {\n","  margin: 0.2em;\n","  border-radius: 0.25em;\n","  color: var(--sklearn-color-text);\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n","  /* Expand drop-down */\n","  max-height: 200px;\n","  max-width: 100%;\n","  overflow: auto;\n","}\n","\n","#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n","  content: \"▾\";\n","}\n","\n","/* Pipeline/ColumnTransformer-specific style */\n","\n","#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator-specific style */\n","\n","/* Colorize estimator box */\n","#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n","#sk-container-id-1 div.sk-label label {\n","  /* The background is the default theme color */\n","  color: var(--sklearn-color-text-on-default-background);\n","}\n","\n","/* On hover, darken the color of the background */\n","#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","/* Label box, darken color on hover, fitted */\n","#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator label */\n","\n","#sk-container-id-1 div.sk-label label {\n","  font-family: monospace;\n","  font-weight: bold;\n","  display: inline-block;\n","  line-height: 1.2em;\n","}\n","\n","#sk-container-id-1 div.sk-label-container {\n","  text-align: center;\n","}\n","\n","/* Estimator-specific */\n","#sk-container-id-1 div.sk-estimator {\n","  font-family: monospace;\n","  border: 1px dotted var(--sklearn-color-border-box);\n","  border-radius: 0.25em;\n","  box-sizing: border-box;\n","  margin-bottom: 0.5em;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-estimator.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","/* on hover */\n","#sk-container-id-1 div.sk-estimator:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-estimator.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Specification for estimator info (e.g. \"i\" and \"?\") */\n","\n","/* Common style for \"i\" and \"?\" */\n","\n",".sk-estimator-doc-link,\n","a:link.sk-estimator-doc-link,\n","a:visited.sk-estimator-doc-link {\n","  float: right;\n","  font-size: smaller;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1em;\n","  height: 1em;\n","  width: 1em;\n","  text-decoration: none !important;\n","  margin-left: 1ex;\n","  /* unfitted */\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-unfitted-level-1);\n","}\n","\n",".sk-estimator-doc-link.fitted,\n","a:link.sk-estimator-doc-link.fitted,\n","a:visited.sk-estimator-doc-link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","/* Span, style for the box shown on hovering the info icon */\n",".sk-estimator-doc-link span {\n","  display: none;\n","  z-index: 9999;\n","  position: relative;\n","  font-weight: normal;\n","  right: .2ex;\n","  padding: .5ex;\n","  margin: .5ex;\n","  width: min-content;\n","  min-width: 20ex;\n","  max-width: 50ex;\n","  color: var(--sklearn-color-text);\n","  box-shadow: 2pt 2pt 4pt #999;\n","  /* unfitted */\n","  background: var(--sklearn-color-unfitted-level-0);\n","  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n","}\n","\n",".sk-estimator-doc-link.fitted span {\n","  /* fitted */\n","  background: var(--sklearn-color-fitted-level-0);\n","  border: var(--sklearn-color-fitted-level-3);\n","}\n","\n",".sk-estimator-doc-link:hover span {\n","  display: block;\n","}\n","\n","/* \"?\"-specific style due to the `<a>` HTML tag */\n","\n","#sk-container-id-1 a.estimator_doc_link {\n","  float: right;\n","  font-size: 1rem;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1rem;\n","  height: 1rem;\n","  width: 1rem;\n","  text-decoration: none;\n","  /* unfitted */\n","  color: var(--sklearn-color-unfitted-level-1);\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","}\n","\n","#sk-container-id-1 a.estimator_doc_link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","#sk-container-id-1 a.estimator_doc_link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","}\n","</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div></div></div>"]},"metadata":{},"execution_count":41}],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.pipeline import Pipeline\n","\n","# Create tokenization and modeling pipeline\n","model_0 = Pipeline([\n","    (\"tfidf\", TfidfVectorizer()), # convert words into numbers using Tfidf\n","    (\"clf\", MultinomialNB())  # model the text\n","])\n","\n","# Fit the pipeline to the training data\n","model_0.fit(train_sentences, train_labels)"]},{"cell_type":"code","source":["# Create tokenization and modeling pipeline (model 0 with 10 percent of training data)\n","#model_0_10_percent = Pipeline([\n","#    (\"tfidf\", TfidfVectorizer()), # convert words into numbers using Tfidf\n","#    (\"clf\", MultinomialNB())  # model the text\n","#])\n","\n","# Fit the pipeline to the training data\n","#model_0_10_percent.fit(train_sentences_10_percent, train_labels_10_percent)"],"metadata":{"id":"Q7W0RQR3SHTS"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1730161914270,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"krWIm3AvHUJV","colab":{"base_uri":"https://localhost:8080/"},"outputId":"651c7cf9-49be-40b3-d055-b23ea41a8712"},"outputs":[{"output_type":"stream","name":"stdout","text":["Our baseline model achieves an accuracy of: 79.27 %\n"]}],"source":["# Evaluate our baseline model\n","baseline_score = model_0.score(val_sentences, val_labels)\n","print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f} %\")"]},{"cell_type":"code","source":["# Evaluate our basline model with 10 percent training data\n","#baseline_score_10_percent = model_0_10_percent.score(val_sentences, val_labels)\n","#print(f\"Our baseline 10 percent model achieves an accuracy of: {baseline_score_10_percent*100:.2f} %\")"],"metadata":{"id":"ysfSnA0JSX0n"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1730161914509,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"VvmFp-b2IDGi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9bd6c5f6-797f-4ebc-9cca-1e7cec42c2ec"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"]},"metadata":{},"execution_count":45}],"source":["# Make predictions\n","baseline_preds = model_0.predict(val_sentences)\n","baseline_preds[:20]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1730161914509,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"8aqfa9GWIZK2","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fe5c9205-e8c1-4a9d-801a-40418a994e7a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 1, ..., 1, 1, 0])"]},"metadata":{},"execution_count":46}],"source":["train_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s8hCkufrI16U"},"outputs":[],"source":["# Create a function that takes in y_true and y_preds and returns a dictionary of the 4 evaluation metrics. (accuracy, precision, recall, F1-score)\n","import numpy as np\n","from sklearn.metrics import f1_score\n","\n","def compare_preds(y_trues, y_preds):\n","  accuracy = tf.keras.metrics.Accuracy()\n","  accuracy.update_state(y_trues, y_preds)\n","\n","  precision = tf.keras.metrics.Precision()\n","  precision.update_state(y_trues, y_preds)\n","\n","  recall = tf.keras.metrics.Recall()\n","  recall.update_state(y_trues, y_preds)\n","\n","  F1score = f1_score(y_trues, y_preds, average=\"macro\")\n","\n","  scores = {\n","      \"accuracy\":accuracy.result(),\n","      \"precision\":precision.result(),\n","      \"recall\":recall.result(),\n","      \"F1score\":F1score\n","  }\n","  return scores\n","\n","  #print(precision.result().numpy())\n","  #print(accuracy.result().numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Beh2DvuBUCrI"},"outputs":[],"source":["from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","def calculate_results(y_true, y_pred):\n","  \"\"\"\n","  Calculates accuracy, precision, recall, f1 score of a binary classification model\n","  \"\"\"\n","  #Calculate accuracy\n","  accuracy = accuracy_score(y_true, y_pred) * 100\n","  #Calculate others\n","  precision, recall, f1score, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n","\n","  results = {\n","      \"accuracy\":accuracy,\n","      \"precision\":precision,\n","      \"recall\":recall,\n","      \"f1score\":f1score\n","  }\n","\n","  return results"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":466,"status":"ok","timestamp":1730161914973,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"2tJhwnXFKHic","colab":{"base_uri":"https://localhost:8080/"},"outputId":"43c0f7c2-a126-4772-b82a-3f407f32b172"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.79265094>,\n"," 'precision': <tf.Tensor: shape=(), dtype=float32, numpy=0.88617885>,\n"," 'recall': <tf.Tensor: shape=(), dtype=float32, numpy=0.62643677>,\n"," 'F1score': 0.7820571304442272}"]},"metadata":{},"execution_count":49}],"source":["#baseline_preds\n","compare_preds(val_labels, baseline_preds)\n","#baseline_preds, val_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yCXpOQ9aRZI7"},"outputs":[],"source":["from helper_functions import calculate_results\n","baseline_results = calculate_results(val_labels, baseline_preds)"]},{"cell_type":"markdown","metadata":{"id":"xkQcmVl4gW2I"},"source":["### Model 1: A Simple Dense Model\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1730161914973,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"5i9yN3XhhrmM","colab":{"base_uri":"https://localhost:8080/","height":70},"outputId":"d16001ff-c4cd-40b9-c238-e45f84e65ce7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n# TensorBoard alternate loading (because site is offline)\\n\\n%load_ext tensorboard\\n\\nimport datetime\\nimport os\\ndef create_tensorboard_callback(experiment_name):\\n  logfit_dir = \"logs/fit/\"\\n  path_experiment = os.path.join(logfit_dir, experiment_name, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\\n  tensorboard_callback = tf.keras.callbacks.TensorBoard(\\n      log_dir=path_experiment\\n  )\\n  print(f\"Saving TensorBoard log files to: {logfit_dir}\")\\n  return tensorboard_callback\\n  '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":51}],"source":["\"\"\"\n","# TensorBoard alternate loading (because site is offline)\n","\n","%load_ext tensorboard\n","\n","import datetime\n","import os\n","def create_tensorboard_callback(experiment_name):\n","  logfit_dir = \"logs/fit/\"\n","  path_experiment = os.path.join(logfit_dir, experiment_name, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n","      log_dir=path_experiment\n","  )\n","  print(f\"Saving TensorBoard log files to: {logfit_dir}\")\n","  return tensorboard_callback\n","  \"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hDw6_eFFifN5"},"outputs":[],"source":["# Create a TensorBoard callback (need to create a new one for each model)\n","from helper_functions import create_tensorboard_callback\n","\n","# Create a directory to save TensorBoard logs\n","SAVE_DIR = \"model_logs\""]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":176,"status":"error","timestamp":1730162276075,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"yDDwNN4Ajby0","colab":{"base_uri":"https://localhost:8080/","height":356},"outputId":"413f318b-8e26-4d91-874e-220258de21d1"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"All `inputs` values must be KerasTensors. Received: inputs=[<KerasTensor: shape=(None, 1) dtype=string (created by layer 'input_6')>] including invalid value KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.string, name='input_6'), name='input_6', description=\"created by layer 'input_6'\") of type <class 'tf_keras.src.engine.keras_tensor.KerasTensor'>","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-59-fdaca2cf1d17>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGlobalAveragePooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#condense the feature vector for each token to one vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Create the output layers, want binary outputs so use sigmoid activation function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"model_1_dense\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/tracking.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mDotNotTrackScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflat_inputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    120\u001b[0m                     \u001b[0;34m\"All `inputs` values must be KerasTensors. Received: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                     \u001b[0;34mf\"inputs={inputs} including invalid value {x} of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: All `inputs` values must be KerasTensors. Received: inputs=[<KerasTensor: shape=(None, 1) dtype=string (created by layer 'input_6')>] including invalid value KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.string, name='input_6'), name='input_6', description=\"created by layer 'input_6'\") of type <class 'tf_keras.src.engine.keras_tensor.KerasTensor'>"]}],"source":["# Build model with the functional API\n","from tf_keras import layers\n","inputs = layers.Input(shape=(1,), dtype=tf.string)  #Inputs are 1-dimensional strings\n","x = text_vectorizer(inputs) #turn the input text into numbers\n","x = embedding(x)    # create an embedding of the numberized inputs\n","x = layers.GlobalAveragePooling1D()(x) #condense the feature vector for each token to one vector\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)  # Create the output layers, want binary outputs so use sigmoid activation function\n","model_1 = tf.keras.Model(inputs,outputs,name=\"model_1_dense\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":165,"status":"error","timestamp":1730162488764,"user":{"displayName":"Mark","userId":"05293542057377705486"},"user_tz":240},"id":"pGdZmRYum0yw","colab":{"base_uri":"https://localhost:8080/","height":141},"outputId":"405f5568-8415-4932-e6e9-d6833e94a0bf"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'model_1' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-60-38d62e0e91d7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model_1' is not defined"]}],"source":["model_1.summary()"]},{"cell_type":"code","source":["\n","# Build model with the sequential API\n","\n","model_1_sequential = tf.keras.Sequential([\n","    tf.keras.Input(shape=(1,), dtype=tf.string),\n","    layers.Dense(1, name=\"input_layer\"),\n","    text_vectorizer,\n","    embedding,\n","    layers.Dense(64,activation=\"relu\"),\n","    layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\")\n","], name=\"model_1_sequential\")\n"],"metadata":{"id":"5C2r4YcoL4qD","executionInfo":{"status":"error","timestamp":1730162497487,"user_tz":240,"elapsed":171,"user":{"displayName":"Mark","userId":"05293542057377705486"}},"colab":{"base_uri":"https://localhost:8080/","height":373},"outputId":"e9ba8089-8507-4800-bea7-a4bf41237da5"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Only instances of `keras.Layer` can be added to a Sequential model. Received: <tf_keras.src.layers.core.dense.Dense object at 0x7c5944800fa0> (of type <class 'tf_keras.src.layers.core.dense.Dense'>)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-61-0382e3408031>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Build model with the sequential API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m model_1_sequential = tf.keras.Sequential([\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"input_layer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, trainable, name)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrebuild\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_rebuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer, rebuild)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morigin_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     96\u001b[0m                 \u001b[0;34m\"Only instances of `keras.Layer` can be \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0;34mf\"added to a Sequential model. Received: {layer} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Only instances of `keras.Layer` can be added to a Sequential model. Received: <tf_keras.src.layers.core.dense.Dense object at 0x7c5944800fa0> (of type <class 'tf_keras.src.layers.core.dense.Dense'>)"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a8-Hg39UoEhl"},"outputs":[],"source":["# Compile model\n","model_1.compile(loss=\"binary_crossentropy\",\n","                optimizer=tf.keras.optimizers.Adam(),\n","                metrics=\"accuracy\")\n","\n","# Fit the model\n","model_1_history = model_1.fit(x=train_sentences,\n","                              y=train_labels,\n","                              epochs=5,\n","                              validation_data=(val_sentences, val_labels),\n","                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n","                                                                     experiment_name=\"model_1_dense\")])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Frjtwwdxq4Xr"},"outputs":[],"source":["# Check the results\n","model_1.evaluate(val_sentences, val_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ky34Uz4ErIVG"},"outputs":[],"source":["# Make some predictions and evaluate those\n","model_1_pred_probs = model_1.predict(val_sentences)\n","model_1_pred_probs.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gdqpT9UAronR"},"outputs":[],"source":["# look at a single prediction\n","model_1_pred_probs[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QR7Ln3UZ8qH-"},"outputs":[],"source":["# look at first 10 predictions\n","model_1_pred_probs[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7awDHK6P80d1"},"outputs":[],"source":["# Convert model prediction probabilities to label format\n","model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n","model_1_preds[:20]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"upc6egOvj9l8"},"outputs":[],"source":["# Convert model prediction probabilities to label format (on TEST dataset)\n","#my_predictions = tf.squeeze(tf.round(my_prediction_probs))\n","#my_predictions[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CQ3Bzj1_9UIX"},"outputs":[],"source":["# Calculate our model_1 results\n","model_1_results = calculate_results(y_true=val_labels,\n","                                    y_pred=model_1_preds)\n","model_1_results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"487qtu08-0fl"},"outputs":[],"source":["import numpy as np\n","np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"]},{"cell_type":"markdown","metadata":{"id":"wKtDnQMx_qjN"},"source":["## Visualizing learned embeddings\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UOGvepA5_87m"},"outputs":[],"source":["# Get the vocabulary from the text vectorization layer\n","words_in_vocab = text_vectorizer.get_vocabulary()\n","len(words_in_vocab), words_in_vocab[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0PUzbk6bAshz"},"outputs":[],"source":["# Model 1 Summary\n","model_1.summary()"]},{"cell_type":"markdown","metadata":{"id":"Dhgh5nRBELFS"},"source":["Now that we've got the embedding matrix our model has learned to represent our tokens, let's see how we can visualize it.\n","\n","To do so, TensorFlow has a handy tool called Project (projector.tensorflow.org) and TF also has an incredible guide on Word Embeddings themselves. (https://www.tensorflow.org/text/guide/word_embeddings)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"njcCVl0iA0Zl"},"outputs":[],"source":["# Get the weight matrix of embedding layer\n","# These are the numerical representation of each time in our training data which have been learned for 5 epochs\n","embed_weights = model_1.get_layer(\"embedding\").get_weights()[0]\n","print(embed_weights.shape)  #same size as vocab size and embedding_dim (output dim of our embedding layer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LgyB35m1E51u"},"outputs":[],"source":["# Create embedding files (we got this from tF word embeddings documentation)\n","import io\n","out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n","out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n","\n","for index, word in enumerate(words_in_vocab):\n","  if index == 0:\n","    continue  # skip 0, it's padding.\n","  vec = embed_weights[index]\n","  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n","  out_m.write(word + \"\\n\")\n","out_v.close()\n","out_m.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SJXgRBbhGmjT"},"outputs":[],"source":["# Download files from Colab to upload to projector\n","#try:\n","#  from google.colab import files\n","#  files.download('vectors.tsv')\n","#  files.download('metadata.tsv')\n","#except Exception:\n","#  pass"]},{"cell_type":"markdown","metadata":{"id":"fG1nmcdiJa7h"},"source":["Jay Alammar illustrated word2vec: https://jalammar.github.io/illustrated-word2vec/"]},{"cell_type":"markdown","metadata":{"id":"OrNyKqPWYDku"},"source":["## Recurrent Neural Network - RNN\n","\n","RNNs are useful sequence data.\n","\n","The premise of a RNN is to use the representation of a previous input to aid the representation of a later input.  \n","\n","** Resources: **\n","For more info> http://introtodeeplearning.com/\n","\n","Chris Olah's intro to LSTMs: https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n","\n","Andre Carpathy's The Unreasonable Effectiveness of RNNs: https://karpathy.github.io/2015/05/21/rnn-effectiveness/"]},{"cell_type":"markdown","metadata":{"id":"xxWELL8FaDCb"},"source":["### Model 2: LSTM\n","\n","LSTM - Long Short Term Memory (one of the most popular LSTM cells)\n","\n","Our structure of an RNN typically looks like this:\n","```\n","Input (text) -> Tokenize -> Embedding -> Layers (RNNs/dense) -> Output (laber probability)\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hDQ6_kOLah3a"},"outputs":[],"source":["# Create an LSTM model\n","from tf_keras import layers\n","inputs = layers.Input(shape=(1,), dtype=\"string\")\n","x = text_vectorizer(inputs)\n","x = embedding(x)\n","#print(x.shape)\n","#x = layers.LSTM(units=64, return_sequences=True)(x) # when you're stacking RNN cells together, you need set return_sequences=True\n","#print(x.shape)\n","x = layers.LSTM(64)(x)\n","#print(x.shape)\n","#x = layers.Dense(64, activation=\"relu\")(x)\n","#print(x.shape)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aWW6gqLjd0R5"},"outputs":[],"source":["# Get a summary\n","model_2.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jYPnBysvd8Re"},"outputs":[],"source":["# Compile the model\n","model_2.compile(loss=\"binary_crossentropy\",\n","                optimizer=tf.keras.optimizers.Adam(),\n","                metrics=\"accuracy\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t2eQvf5eeIXo"},"outputs":[],"source":["# Fit the model\n","model_2_history = model_2.fit(train_sentences,\n","                              train_labels,\n","                              epochs=5,\n","                              validation_data=(val_sentences,val_labels),\n","                              callbacks=[create_tensorboard_callback(SAVE_DIR,\"model_2_LSTM\")])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lyTEmrHse5Zx"},"outputs":[],"source":["# Make predictions with LSTM model\n","model_2_pred_probs = model_2.predict(val_sentences)\n","model_2_pred_probs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dV1GwrsIfTmg"},"outputs":[],"source":["# Convert model_2 pred probs to labels\n","model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n","print(model_2_preds.shape)\n","model_2_preds[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m9YF0vidgZ65"},"outputs":[],"source":["# Calculate model_2 results\n","model_2_results = calculate_results(y_true=val_labels,\n","                                    y_pred=model_2_preds)\n","model_2_results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"biNhx9dQgx67"},"outputs":[],"source":["baseline_results"]},{"cell_type":"markdown","metadata":{"id":"tMPY-Svljx9x"},"source":["### Model 3: GRU\n","\n","Another popular and effective RNN component is GRU (Gated Recurrent Unit)\n","\n","The GRU cell has similar feature to the LSTM cell but has less parameters."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hhSDklk6kd_U"},"outputs":[],"source":["# Build an RNN using the GRU cell\n","from tf_keras import layers\n","inputs = layers.Input(shape=(1,), dtype=tf.string)\n","x = text_vectorizer(inputs)\n","x = embedding(x)\n","x = layers.GRU(64)(x)\n","#print(x.shape)\n","#x = layers.GRU(64, return_sequences=True)(x) # if you want to stack recurrent layers on top of each other, you need return_sequences=True\n","#print(x.shape)\n","#x = layers.LSTM(42, return_sequences=True)(x)\n","#print(x.shape)\n","#x = layers.GRU(64)(x)\n","#print(x.shape)\n","#x = layers.Dense(64, activation=\"relu\")(x)\n","#x = layers.GlobalAveragePooling1D()(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9jZl-GObmjkp"},"outputs":[],"source":["model_3.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A5xVfiPQpCS6"},"outputs":[],"source":["model_3.compile(loss=\"binary_crossentropy\",\n","                optimizer=tf.keras.optimizers.Adam(),\n","                metrics=\"accuracy\")\n","\n","model_3_history = model_3.fit(train_sentences,\n","            train_labels,\n","            epochs=5,\n","            validation_data=(val_sentences,val_labels),\n","            callbacks=[create_tensorboard_callback(SAVE_DIR,\n","                                                   \"model_3_GRU\")])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WVIGjfSypuBf"},"outputs":[],"source":["# Make some predictions with our GRU model\n","model_3_pred_probs = model_3.predict(val_sentences)\n","model_3_pred_probs[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aP1Ne_xxqDaw"},"outputs":[],"source":["model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n","model_3_preds[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jU7FHPNAqQYk"},"outputs":[],"source":["# Calculate model 3 results\n","model_3_results = calculate_results(val_labels, model_3_preds)\n","model_3_results"]},{"cell_type":"markdown","metadata":{"id":"nbq9p_zhrXiL"},"source":["### Model 4: a bidirectional RNN\n","\n","Normal RNNs go from left to right, like reading English. However a bidirectional RNN goes from right to left + left to right."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4krhoitcrZzd"},"outputs":[],"source":["# Build bidirectional RNN in TensorFlow\n","\n","from tensorflow import keras\n","from tf_keras import layers\n","\n","#model_4 = keras.Sequential()\n","#model_4.add(layers.Bidirectional(layers.LSTM(10, return_sequences=True),\n","#                          input_shape=(1,)))\n","##model_4.add(layers.LSTM(10))\n","#model_4.add(layers.Dense(1,))\n","#model_4.add(layers.Activation(\"softmax\"))\n","\n","inputs = layers.Input(shape=(1,), dtype=\"string\")\n","x = text_vectorizer(inputs)\n","x = embedding(x)\n","#x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n","x = layers.Bidirectional(layers.LSTM(64))(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model_4 = tf.keras.Model(inputs,outputs,name=\"model_4_bidirectional\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TnwEUNhttae4"},"outputs":[],"source":["# Compile\n","model_4.compile(loss=\"binary_crossentropy\",\n","                optimizer=tf.keras.optimizers.Adam(),\n","                metrics=\"accuracy\")\n","\n","model_4.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-xzZUFDFt4MU"},"outputs":[],"source":["# Fit the model\n","\n","model_4_history = model_4.fit(train_sentences,\n","                              train_labels,\n","                              epochs=5,\n","                              validation_data=(val_sentences, val_labels),\n","                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n","                                                                     \"model_4_BIDIRECTIONAL\")])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z2nzJ1w97wpz"},"outputs":[],"source":["# Make predictions with our bidirectional model\n","model_4_pred_probs = model_4.predict(val_sentences)\n","model_4_pred_probs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HuBiOxtI8P9P"},"outputs":[],"source":["# Convert pred_probs to pred_labels\n","model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n","model_4_preds[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Felr8gow8rn4"},"outputs":[],"source":["# Calculate results\n","model_4_results = calculate_results(val_labels, model_4_preds)\n","model_4_results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_YxFgKxl85jR"},"outputs":[],"source":["baseline_results"]},{"cell_type":"markdown","metadata":{"id":"XFblcma788O8"},"source":["## Convolutional Neural Networks for Text (and other types of sequences)\n","\n","We've used CNNs for images but images are typically 2D (height x width), however our text data is 1s.\n","\n","Previously we've used Conv2D for our image data, but now we will use Conv1D.\n","\n","The typical structure of a Conv1D model for sequences (in our case text) looks like this:\n","\n","```\n","Inputs (text) -> Tokenization -> Embedding -> Layer(s) (typically Conv1D + Pooling) -> Outputs (class probabilities)"]},{"cell_type":"markdown","metadata":{"id":"X_pHF09m97oQ"},"source":["### Model 5: Conv1D ###\n","\n","For different explanations of parameters see:\n","* https://poloclub.github.io/cnn-explainer/ (this is for 2d but can relate to 1d data)\n","* Difference between \"same\" and \"valid\" padding: https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KzmvYkJV-JMm"},"outputs":[],"source":["# Test out our embedding layer, Conv1D layer and max pooling\n","from tf_keras import layers\n","embedding_test = embedding(text_vectorizer([\"this is a test sentence\"])) # turn target sequence into an embedding\n","conv_1d = layers.Conv1D(filters=32,\n","                        kernel_size=5,  #this is also referred to as an ngram of 5 (meaning it looks at 5 words at a time)\n","                        activation=\"relu\",\n","                        padding=\"valid\")\n","\n","conv_1d_output = conv_1d(embedding_test) #pass test embedding through Conv1d layer\n","max_pool = layers.GlobalMaxPool1D()\n","max_pool_output = max_pool(conv_1d_output) # equivalent to \"get the most important feature or get the feature with the highest value\"\n","\n","embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Qddyx_pEzG0"},"outputs":[],"source":["embedding_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gMS1xYLAE2gT"},"outputs":[],"source":["conv_1d_output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3yQ15XL9FZlr"},"outputs":[],"source":["max_pool_output"]},{"cell_type":"markdown","metadata":{"id":"e3ED2MqMHGck"},"source":["<tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n","array([[0.07606642, 0.12893276, 0.04685416, 0.03963244, 0.03266621,\n","        0.02844372, 0.03377763, 0.05978166, 0.07423814, 0.04644558,\n","        0.07084233, 0.06454812, 0.05894979, 0.08935377, 0.06154132,\n","        0.02082836, 0.10778599, 0.01146116, 0.1356203 , 0.05557969,\n","        0.05341431, 0.12952252, 0.0616392 , 0.08001035, 0.05808549,\n","        0.09503245, 0.06640893, 0.06298555, 0.05060241, 0.00689121,\n","        0.07780851, 0.03054681]], dtype=float32)>\n","      "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_fAyskfHBlmp"},"outputs":[],"source":["# Create 1-dimensional convolutional layer to model sequences\n","from tf_keras import layers\n","\n","inputs = layers.Input(shape=(1,), dtype=tf.string)\n","x = text_vectorizer(inputs)\n","x = embedding(x)\n","#x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n","x = layers.Conv1D(filters=64, kernel_size=5, activation=\"relu\", padding=\"valid\", strides=1)(x)\n","x = layers.GlobalMaxPool1D()(x)\n","print(x.shape)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model_5 = tf.keras.Model(inputs,outputs,name=\"model_5_Conv1D\")\n","\n","# Compile Conv1D\n","model_5.compile(loss=\"binary_crossentropy\",\n","                optimizer=tf.keras.optimizers.Adam(),\n","                metrics=\"accuracy\")\n","\n","# Get a summary\n","model_5.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fmTL-dh1GdfH"},"outputs":[],"source":["# Fit the model\n","model_5_history = model_5.fit(train_sentences,\n","                              train_labels,\n","                              epochs=5,\n","                              validation_data=(val_sentences, val_labels),\n","                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n","                                                                     \"model_5_CONV1D\")])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1GB3IxmuIDyt"},"outputs":[],"source":["# Make some predictions with our Conv1D model\n","model_5_pred_probs = model_5.predict(val_sentences)\n","model_5_pred_probs[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2MBkJP_WKDW8"},"outputs":[],"source":["model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n","model_5_preds[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HiV0VpUJKUcK"},"outputs":[],"source":["model_5_results =calculate_results(val_labels, model_5_preds)"]},{"cell_type":"markdown","metadata":{"id":"D8Ao26tmO_ZY"},"source":["## Model 6: TensorFlow Hub Pretrained Sentence Encoder\n","\n","Now that we've built a few of our own models, let's try and use transfer learning for NLP, specifically using TensorFlowHub's universal sentence encoder."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ze9dWF7qP7VK"},"outputs":[],"source":["sample_sentence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x3wGqw7bPJpR"},"outputs":[],"source":["import tensorflow_hub as hub\n","\n","embed = hub.load(\"https://www.kaggle.com/models/google/universal-sentence-encoder/frameworks/TensorFlow2/variations/universal-sentence-encoder/versions/2\")\n","embeddings = embed([sample_sentence,\n","    \"The quick brown fox jumps over the lazy dog.\",\n","    \"I am a sentence for which I would like to get its embedding\"])\n","\n","print(embeddings[0][:50])\n","\n","# The following are example embedding output of 512 dimensions per sentence\n","# Embedding for: The quick brown fox jumps over the lazy dog.\n","# [-0.03133016 -0.06338634 -0.01607501, ...]\n","# Embedding for: I am a sentence for which I would like to get its embedding.\n","# [0.05080863 -0.0165243   0.01573782, ...]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P3m04c9UQfpQ"},"outputs":[],"source":["embeddings[0].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vMFb0_UyQrzs"},"outputs":[],"source":["# Create Keras layer using the pretrained USE layer from TensorFlow Hub\n","sentence_encoder_layer = hub.KerasLayer(\"https://www.kaggle.com/models/google/universal-sentence-encoder/frameworks/TensorFlow2/variations/universal-sentence-encoder/versions/2\",\n","                                        input_shape=[],\n","                                        dtype=tf.string,\n","                                        trainable=False,\n","                                        name=\"USE\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q-dVJhxjYLOv"},"outputs":[],"source":["# Create model using the sequential API\n","model_6 = tf.keras.Sequential([\n","    sentence_encoder_layer,\n","    layers.Dense(64, activation=\"relu\"),\n","    layers.Dense(64, activation=\"relu\"),\n","    layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\"),\n","], name=\"model_6_USE\")\n","\n","# Compile the model\n","model_6.compile(loss=\"binary_crossentropy\",\n","                optimizer=tf.keras.optimizers.Adam(),\n","                metrics=\"accuracy\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jZRxtipbaIg-"},"outputs":[],"source":["model_6.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Nt4vWZ8a2Ll"},"outputs":[],"source":["# Train a classifier on top of USE parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UvU9XHjcZWXZ"},"outputs":[],"source":["# Fit the model\n","model_6_history = model_6.fit(train_sentences,\n","                              train_labels,\n","                              epochs=5,\n","                              validation_data=(val_sentences, val_labels),\n","                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n","                                                                     \"model_6_encoder\")])\n","\n","# Fit the model on validation set\n","model_6_history_validation = model_6.fit(val_sentences,\n","                                         val_labels,\n","                                         epochs=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ge0usBy_bqFS"},"outputs":[],"source":["# Make predictions with USE TF Hub Model\n","model_6_pred_probs = model_6.predict(val_sentences)\n","model_6_pred_probs[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LsWhtPTGcBKE"},"outputs":[],"source":["# Convert prediction probabilities to labels\n","model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n","model_6_preds[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nvqe6vjhcSL_"},"outputs":[],"source":["# Calculate model_6 performance metrics\n","model_6_results = calculate_results(val_labels, model_6_preds)\n","model_6_results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w07d_1exc0bw"},"outputs":[],"source":["baseline_results"]},{"cell_type":"markdown","metadata":{"id":"OmS5DPswom5H"},"source":["## Model 7: TF Hub Pretrained USE but with 10% of training data\n","\n","Transfer learning really helps when you don't have a large data set.  \n","To see how our model performs on a small data set, let's replicate `model_6` except we'll train it on 10% of the data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iYh97xOMpHtC"},"outputs":[],"source":["## NOTE: Making data splits like below leads to data leakage (model_7 trained on 10% data outperforms model_6 trained on 100% data)\n","## DO NOT MAKE DATA SPLITS THAT LEAK DATA FROM VALIDATION/TEST SETS INTO TRAINING SET\n","\n","# Create subsets of 10% of the training data.\n","train_10_percent = train_df_shuffled\n","train_10_percent = train_10_percent[[\"text\",\"target\"]].sample(frac=0.1, random_state=42)\n","#len(train_10_percent), train_10_percent.head()\n","train_sentences_10_percent = train_10_percent[\"text\"].to_list()\n","train_labels_10_percent = train_10_percent[\"target\"].to_list()\n","len(train_sentences_10_percent), len(train_labels_10_percent)"]},{"cell_type":"markdown","metadata":{"id":"ijZ7YwDg-UNJ"},"source":["> 🔑 ** NOTE: ** Be very careful when making train/val/test splits that you don't leak data across the datasets.  Otherwise your model evaluation metrics will be wrong.  \n","If something looks to good to be true, a model trained on 10% of the data outperforming a model trained on the same model trained on 100% of the data, trust your gut and go back through where the error may lie."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BD71UNh86gHj"},"outputs":[],"source":["# Making a better dataset split (no data leakage)\n","train_10_percent_split = int(0.1 * len(train_sentences))\n","train_sentences_10_percent = train_sentences[:train_10_percent_split]\n","train_labels_10_percent = train_labels[:train_10_percent_split]\n","len(train_labels_10_percent)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MVYYw4Vg78kw"},"outputs":[],"source":["pd.Series(np.array(train_labels_10_percent)).value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k-WacNeO7D8y"},"outputs":[],"source":["train_10_percent[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"72ftpsO4rrQj"},"outputs":[],"source":["# Check the number of targets in our subset of data\n","train_10_percent[\"target\"].value_counts()"]},{"cell_type":"markdown","metadata":{"id":"ipeDXOu3svTR"},"source":["## Model 7:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wFf6PhLasxBc"},"outputs":[],"source":["# Create model 7\n","model_7 = tf.keras.Sequential([\n","    sentence_encoder_layer,\n","    layers.Dense(64,activation=\"relu\"),\n","    layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\")\n","], name=\"model_7_USE_10_percent\")\n","\n","# Compile model 7\n","model_7.compile(loss=\"binary_crossentropy\",\n","                optimizer=tf.keras.optimizers.Adam(),\n","                metrics=\"accuracy\")\n","\n","model_7.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cswsF2Twto48"},"outputs":[],"source":["# Fit the model\n","history_model_7 = model_7.fit(train_sentences_10_percent,\n","                              train_labels_10_percent,\n","                              epochs=5,\n","                              validation_data=(val_sentences, val_labels),\n","                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n","                                                                     \"tf_hub_sentence_encoder_10_percent_correct_split\")])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HBeAktuNvLGs"},"outputs":[],"source":["#cloned model 7\n","#model_7_clone = tf.keras.models.clone_model(model_6)\n","\n","# Compile model 7 clone\n","#model_7_clone.compile(loss=\"binary_crossentropy\",\n","#                optimizer=tf.keras.optimizers.Adam(),\n","#                metrics=\"accuracy\")\n","\n","#model_7_clone.summary()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LLhf_o12vrle"},"outputs":[],"source":["# Fit the cloned model\n","#history_model_7_clone = model_7_clone.fit(train_sentences_10_percent,\n","#                              train_labels_10_percent,\n","#                              epochs=5,\n","#                              validation_data=(val_sentences, val_labels),\n","#                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n","#                                                                     \"model_7_cloned_encoder\")])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h_ruvpb_yXwF"},"outputs":[],"source":["# Get predictions model 7\n","#model_7_clone_preds = model_7_clone.predict(val_sentences)\n","#model_7_clone_preds[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CeyP2bNEynTZ"},"outputs":[],"source":["#model_7_clone_pred_probs = tf.squeeze(tf.round(model_7_clone_preds))\n","#model_7_clone_pred_probs[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xH2zpTUSyxRZ"},"outputs":[],"source":["# Turn pred probs into labels\n","#model_7_clone_results = calculate_results(val_labels, model_7_clone_pred_probs)\n","#model_7_clone_results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oL6oiRKPzUKN"},"outputs":[],"source":["baseline_results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6EBz2Xp1zeg1"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"134kdtDU_Gj_"},"source":["## Comparing the performance of each our models ##\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P9u4vKII_R_p"},"outputs":[],"source":["# Combine model results into a dataframe\n","all_model_results = pd.DataFrame({\"0_baseline\": baseline_results,\n","                                  \"1_simple_dense\": model_1_results,\n","                                  \"2_lstm\": model_2_results,\n","                                  \"3_gru\": model_3_results,\n","                                  \"4_bidirectional\": model_4_results,\n","                                  \"5_conv1d\": model_5_results,\n","                                  \"6_tf_hub_use_encoder\": model_6_results,\n","                                  \"7_tf_hub_use_encoder_10_percent\": \"hi\",#model_7_clone_results\n","                                  })\n","all_model_results = all_model_results.transpose()\n","all_model_results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wS99B-Vp_hPZ"},"outputs":[],"source":["# Reduce the accuracy to the same scale as the other metrics\n","#all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"] / 100\n","#all_model_results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"41eLWah9BdKP"},"outputs":[],"source":["# Plot and compare all of the model results\n","#all_model_results.plot(kind=\"bar\", figsize=(10,7)).legend(bbox_to_anchor=(1.0,1.0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uqsI-6-bChii"},"outputs":[],"source":["# Sort model results by F1-score\n","#all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(8,4))"]},{"cell_type":"markdown","metadata":{"id":"boSR9O7dFVOV"},"source":["## Uploading our model training logs to TensorBoard.Dev\n","\n","We can further inspect our model's performance using tensorboard.dev"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E85dnxE_F99D"},"outputs":[],"source":["# Load the TensorBoard notebook extension\n","%load_ext tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BB7dSd5UF-gf"},"outputs":[],"source":["import datetime, os\n","\n","logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n","\n","#history_model_8_clone = model_7_clone.fit(train_sentences_10_percent,\n","#                              train_labels_10_percent,\n","#                              epochs=5,\n","#                              validation_data=(val_sentences, val_labels),\n","#                              callbacks=[tensorboard_callback])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u-XO-gJQM5kL"},"outputs":[],"source":["# View TensorBoard logs of tranfer learning modelling experiments (plus all other models)\n","# Upload TensorBoard.Dev records\n","!tensorboard dev upload"]},{"cell_type":"markdown","metadata":{"id":"iBASxfs_N341"},"source":["Now that I've ran the cell above, my modelling experiments are visible on TensorBoard.dev.  \n","\n","** 📃 Note: ** TensorBoard is good for quickly showing experiments but for larger projects use Weights and Biases: https://wandb.ai/site"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TC1sxoupNJC2"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"xpJBcavNPnsS"},"source":["## Saving and loading a trained model: ##\n","\n","There are two main formats to save a model to in TensorFlow:\n","1. HDF5 format\n","2. The `SavedModel` format (this is the default when using TensorFlow)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LkLuXlp9P-U-"},"outputs":[],"source":["model_6_results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BPU70dgUQAl4"},"outputs":[],"source":["# Save our TF Hub Sentence Encoder model to HDF5 format\n","model_6.save(\"model_6.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MugioXoKQWaE"},"outputs":[],"source":["# Load model with custom Hub Layer (requires HDF5 format)\n","import tensorflow_hub as hub\n","loaded_model_6 = tf.keras.models.load_model(\"model_6.h5\",\n","                                            custom_objects={\"KerasLayer\": hub.KerasLayer})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RAkDBZAIRJRM"},"outputs":[],"source":["# How does our loaded model perform?\n","loaded_model_6.evaluate(val_sentences, val_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lX9D8sDaRXV_"},"outputs":[],"source":["model_6_results"]},{"cell_type":"markdown","metadata":{"id":"k98zBs3iRrTi"},"source":["Now let's save to the `SavedModel` format... (more on this here:\n","https://www.tensorflow.org/tutorials/keras/save_and_load)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W_wrQlbMRw1z"},"outputs":[],"source":["# Save TF Hub Sentence Encoder model to SavedModel format (default)\n","model_6.save(\"model_6_SavedModel_format\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lw1zcwUoR73u"},"outputs":[],"source":["# Load in a model from the SavedModel format.\n","loaded_model_6_savedmodel = tf.keras.models.load_model(\"model_6_SavedModel_format\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vWI1j-TwS8eK"},"outputs":[],"source":["loaded_model_6_savedmodel.evaluate(val_sentences, val_labels)"]},{"cell_type":"markdown","metadata":{"id":"7BWp0ZvLV4Lu"},"source":["## Find the most wrong examples\n","\n","* If our best model still isnt perfect, which examples is it still geting wrong?  And of these wrong examples, which ones is it getting most wrong?\n","So the ones with the prediction probability closest to the opposite clas\n","For example if a sample should have a label of 0, but our model predicts a prediction probability of 0.999 (really close to 1) and vice versa"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pi2NH3k5WuG2"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gwq95bmNTHMV"},"outputs":[],"source":["make_confusion_matrix(val_labels, model_6_preds)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QGiaHpPCZ2jD"},"outputs":[],"source":["# Download a pretrained model from Google Storage\n","!wget https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n","!unzip 08_model_6_USE_feature_extractor.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ha3oCh9Pacrq"},"outputs":[],"source":["model_6_daniels = tf.keras.models.load_model(\"08_model_6_USE_feature_extractor\")\n","model_6_daniels.evaluate(val_sentences, val_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7T-P4zeNbAJX"},"outputs":[],"source":["model_6_daniels_pred_probs = model_6_daniels.predict(val_sentences)\n","model_6_daniels_preds = tf.squeeze(tf.round(model_6_daniels_pred_probs))\n","model_6_daniels_preds[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lr4hblixfRTh"},"outputs":[],"source":["# Create a DataFrame with validation sentences, validation labels, and best performing model prediction labels + probabilities\n","\n","import pandas as pd\n","\n","max_preds_disaster_imported = pd.DataFrame({\"text\":val_sentences,\n","                                            \"y_true\":val_labels,\n","                                            \"y_pred\":model_6_daniels_preds,\n","                                            \"pred_conf\":tf.squeeze(model_6_daniels_pred_probs)})\n","max_preds_disaster_imported"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RwcVi5EhlKeN"},"outputs":[],"source":["# Create a dataframe with TEST sentences and predictions\n","\n","#test_preds_disaster = pd.DataFrame({\"text\":test_df_shuffled[\"text\"].to_numpy(),\n","#                                    \"pred\":my_predictions,\n","#                                    \"prob\":tf.squeeze(my_prediction_probs)})\n","#test_preds_disaster"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3jwIUYy2g6X0"},"outputs":[],"source":["max_preds_disaster_imported[\"pred_correct\"] = max_preds_disaster_imported[\"y_true\"] == max_preds_disaster_imported[\"y_pred\"]\n","max_preds_disaster_imported"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jlOJWErShWCh"},"outputs":[],"source":["top_100_wrong = max_preds_disaster_imported[max_preds_disaster_imported[\"pred_correct\"]==False].sort_values(\"pred_conf\", ascending=False)[:100]\n","\n","top_100_wrong[:10].style.set_caption(\"my title\")\n","top_100_wrong[\"y_true\"] = top_100_wrong[\"y_true\"].replace({0:\"not disaster\",\n","                                                           1:\"disaster\"})\n","top_100_wrong[\"y_pred\"] = top_100_wrong[\"y_pred\"].replace({0:\"not disaster\",\n","                                                           1:\"disaster\"})\n","top_100_wrong"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5cnLV-BLnCvV"},"outputs":[],"source":["#test_preds_disaster_converted = test_preds_disaster.sort_values(\"prob\", ascending=False)\n","#test_preds_disaster_converted[\"pred\"] = test_preds_disaster[\"pred\"].replace({0:\"not disaster\",\n","#                                                                             1:\"disaster\"})\n","#test_preds_disaster_converted"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F3Y-F8K9n9Lh"},"outputs":[],"source":["# Check the highest probability disasters from test data set\n","#for row in test_preds_disaster_converted[:10].itertuples():\n","#  _, text, pred, prob = row\n","#  print(f\"Pred: {pred}, Prob: {prob}\")\n","#  print(f\"Text: \\n{text}\\n\")\n","#  print(\"----\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ELPqFel3qJZc"},"outputs":[],"source":["# Check the lowest probability disasters from test data set\n","#for row in test_preds_disaster_converted[:-10].itertuples():\n","#  _, text, pred, prob = row\n","#  print(f\"Pred: {pred}, Prob: {prob}\")\n","#  print(f\"Text: \\n{text}\\n\")\n","#  print(\"----\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c9rh21KeUxsD"},"outputs":[],"source":["import pandas as pd\n","\n","max_preds_disaster = pd.DataFrame({\"y_true\":val_labels,\n","                                   \"y_pred\":model_6_preds,\n","                                   \"pred_conf\":model_6_pred_probs.max(axis=1)})\n","max_preds_disaster"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FeqKrlbiZEMH"},"outputs":[],"source":["# Check the false positives (model predicted 1 when should have been 0)\n","for row in top_100_wrong[:10].itertuples():\n","  _, text, y_true, y_pred, pred_conf, _ = row\n","  print(f\"Label: {y_true}, Pred: {y_pred,}, Prob: {pred_conf}\")\n","  print(f\"Text: \\n{text}\\n\")\n","  print(\"----\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4JyzvVvnhaXl"},"outputs":[],"source":["# Check the false negatives (model predicted 0 when should have been 1)\n","for row in top_100_wrong[-10:].itertuples():\n","  _, text, y_true, y_pred, pred_conf, _ = row\n","  print(f\"Label: {y_true}, Pred: {y_pred}, Prob: {pred_conf}\")\n","  print(f\"Text: \\n{text}\\n\")\n","  print(\"----\\n\")"]},{"cell_type":"markdown","metadata":{"id":"FZzyt-E4sW7R"},"source":["## Your challenge: Predicting on tweets from the wild\n","\n","Pass the tweets through the model... is the tweet a disaster or not a disaster?"]},{"cell_type":"markdown","source":["# New Section"],"metadata":{"id":"fmNZSqeF_CsY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fqIAPnmJsqoF"},"outputs":[],"source":["#1. Prep data\n","random_tweets = [\"Pakistan responded by striking Iranian territory.\",\n","                 \"Only a handful of mostly middle-ranking police and other officials were indicted on criminal negligence and similar charges last year, while top government officials, like the home minister, were cleared of wrongdoing.\",\n","                 \"On the court, Andreeva is a series of beguiling contradictions.\",\n","                 \"It said that its priority was to protect civilians and, through diplomacy with American, Arab and African partners, to seek a peaceful solution to the conflict.\",\n","                 \"The trouble, critics concurred, was that Mr. Schickele was a victim of his own prodigious ability as a pasticheur.\",\n","                 \"As my breath returned to its regular rate, Haas told me that he valued my music, but that I would need to start believing in myself.\"]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hlRz90t8s5GM"},"outputs":[],"source":["custom_prediction_probs = model_6.predict(random_tweets)\n","custom_prediction_probs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O1vGNKGjtafo"},"outputs":[],"source":["for random_tweet in random_tweets:\n","  pred_prob = model_6.predict([random_tweet])\n","  pred = tf.round(pred_prob)\n","  print(f\"Pred: {pred}, Prob:{pred_prob}\")\n","  print(f\"Text: {random_tweet}\")\n","  print(f\"---------\")"]},{"cell_type":"markdown","source":["## Extracurricular"],"metadata":{"id":"JAS_GgjT_Nkd"}},{"cell_type":"code","source":["# Build model with the sequential API\n","\n","model_1_sequential = tf.keras.Sequential([\n","    tf.keras.Input(shape=(1,), dtype=tf.string, name=\"input_layer0\"),\n","    #layers.Dense(1, name=\"input_layer\"),\n","    text_vectorizer,\n","    embedding,\n","    layers.GlobalAveragePooling1D(),\n","    layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\")\n","], name=\"model_1_sequential\")\n","\n","model_1_sequential.summary()"],"metadata":{"id":"4oS63JyP_PLz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compile the model\n","model_1_sequential.compile(loss=\"binary_crossentropy\",\n","                           optimizer=tf.keras.optimizers.Adam(),\n","                           metrics=\"accuracy\")\n","\n","# Fit the model\n","model_1_sequential.fit(train_sentences,\n","                       train_labels,\n","                       epochs=5,\n","                       validation_data=(val_sentences, val_labels),\n","                       callbacks=[create_tensorboard_callback(SAVE_DIR,\n","                                                              \"model_1_sequential\")])"],"metadata":{"id":"QI23lmPC_tmX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create an LSTM model - Model 2 with Sequential\n","\n","model_2_sequential = tf.keras.Sequential([\n","    layers.Input(shape=(1,), dtype=\"string\"),\n","    text_vectorizer,\n","    embedding,\n","    layers.LSTM(64),\n","    layers.Dense(1, activation=\"sigmoid\", name=\"model_2_LSTM_sequential\")\n","])"],"metadata":{"id":"c5OQCzyyAe8t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compile model 2 sequential\n","model_2_sequential.compile(loss=\"binary_crossentropy\",\n","                           optimizer=tf.keras.optimizers.Adam(),\n","                           metrics=\"accuracy\")\n","\n","model_2_sequential.fit(train_sentences,\n","                       train_labels,\n","                       epochs=5,\n","                       validation_data=(val_sentences,val_labels),\n","                       callbacks=[create_tensorboard_callback(SAVE_DIR,\n","                                                              \"model_2_sequential_log\")])"],"metadata":{"id":"Zp6_5yj2OjPr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create 1-dimensional convolutional layer to model sequences (model 5 but Sequential)\n","model_5_sequential = tf.keras.Sequential([\n","    layers.Input(shape=(1,), dtype=tf.string, name=\"input_layer\"),\n","    text_vectorizer,\n","    embedding,\n","    layers.Conv1D(filters=64, kernel_size=5, activation=\"relu\", padding=\"valid\", strides=1),\n","    layers.GlobalMaxPool1D(),\n","    layers.Dense(1, activation=\"sigmoid\")\n","])\n","\n","model_5_sequential.compile(loss=\"binary_crossentropy\",\n","                           optimizer=tf.keras.optimizers.Adam(),\n","                           metrics=\"accuracy\")\n","\n","model_5_sequential.summary()\n","\n","model_5_sequential.fit(train_sentences,\n","                       train_labels,\n","                       epochs=5,\n","                       validation_data=(val_sentences, val_labels),\n","                       callbacks=[create_tensorboard_callback(SAVE_DIR,\n","                                                              \"model_5_sequential_logs\")])"],"metadata":{"id":"rRzTlKbUPAjR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create Keras layer using the pretrained USE layer from TensorFlow Hub with Trainable=TRUE\n","#sentence_encoder_layer_trainable = hub.KerasLayer(\"https://www.kaggle.com/models/google/universal-sentence-encoder/frameworks/TensorFlow2/variations/universal-sentence-encoder/versions/2\",\n","#                                        input_shape=[],\n","#                                        dtype=tf.string,\n","#                                        trainable=True,\n","#                                        name=\"USE\")"],"metadata":{"id":"hEsuPXLaQaow"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create model using sequential API and USE layer is trainable now\n","#model_6_trainable = tf.keras.Sequential([\n","#    sentence_encoder_layer_trainable,\n","#    layers.Dense(64, activation=\"relu\"),\n","#    layers.Dense(64, activation=\"relu\"),\n","#    layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\"),\n","#    ],\n","#                                        name=\"model_6_USE_trainable\")"],"metadata":{"id":"T0h1E7PsTorb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# compile model 6 trainable\n","#model_6_trainable.compile(loss=\"binary_crossentropy\",\n","#                          optimizer=tf.keras.optimizers.Adam(),\n","#                          metrics=\"accuracy\")\n","\n","#model_6_trainable_history = model_6_trainable.fit(train_sentences,\n","#                                                  train_labels,\n","#                                                  epochs=5,\n","#                                                  validation_data=(val_sentences, val_labels),\n","#                                                  callbacks=[create_tensorboard_callback(SAVE_DIR,\n","#                                                                                         \"model_6_trainable_logs\")])"],"metadata":{"id":"kUpm9-vtUBYQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#model_6_trainable.evaluate(val_sentences, val_labels)"],"metadata":{"id":"U2xo-nJSUX21"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Extracurricular exercise 4:  Train the best model on the whole training data and not on split\n","\n","# Use train_test_split to split the data into training and validation sets (except no validation split on this one)\n","train_sentences2, val_sentences2, train_labels2, val_labels2 = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n","                                                         train_df_shuffled[\"target\"].to_numpy(),\n","                                                         test_size=1,\n","                                                         random_state=42)\n","\n","len(train_sentences2), len(train_labels2), len(val_sentences2), len(val_labels2)\n","\n","\n"],"metadata":{"id":"43NHlF8MThZl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Build the model\n","#model_6_full = tf.keras.Sequential([\n","#    sentence_encoder_layer,\n","#    layers.Dense(64, activation=\"relu\"),\n","#    layers.Dense(64, activation=\"relu\"),\n","#    layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\"),\n","#], name=\"model_6_USE_full_training\")\n","\n","#model_6_full.compile(loss=\"binary_crossentropy\",\n","#                     optimizer=tf.keras.optimizers.Adam(),\n","#                     metrics=\"accuracy\")\n","\n","#history_model_6_full = model_6_full.fit(train_sentences2,\n","#                                        train_labels2,\n","#                                        epochs=5,\n","#                                        callbacks=[create_tensorboard_callback(SAVE_DIR,\n","#                                                                               \"model_6_full_training_logs\")])"],"metadata":{"id":"Og0sRGZiXDme"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#model_6_full.evaluate(val_sentences, val_labels)"],"metadata":{"id":"piLY26_MYRgu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Make predictions on the test dataset\n","#model_6_full_pred_probs = model_6_full.predict(test_df_shuffled[\"text\"].to_numpy())\n","#model_6_full_pred_probs"],"metadata":{"id":"gK9VUUSXYw1x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#model_6_full_preds = tf.squeeze(tf.round(model_6_full_pred_probs))\n","#model_6_full_preds"],"metadata":{"id":"pUf67BwoaWRd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_df_shuffled"],"metadata":{"id":"E0l0MICaamZb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# convert model_6_full_preds into ints\n","#model_6_full_preds_ints = [int(item) for item in model_6_full_preds]\n","#print(model_6_full_preds_ints)\n","\n","# adding the preds column from model_6_full to format it into the sample_submission.csv format\n","\n","#test_df_shuffled[\"preds\"] = model_6_full_preds\n","#test_df_shuffled"],"metadata":{"id":"fgl6WqPLb1K0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# drop unnecessary columns\n","#test_df_shuffled = test_df_shuffled.drop(columns=[\"keyword\", \"location\", \"text\"])\n","\n","\n","#test_df_shuffled = test_df_shuffled.rename(columns={\"preds\":\"target\"})\n","#test_df_shuffled"],"metadata":{"id":"jqerEjyldsLA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# convert the target column to ints because pandas made it a float for some reason\n","#test_df_shuffled[\"target\"] = test_df_shuffled[\"target\"].astype(int)\n","#sorted_df = test_df_shuffled.sort_values(\"id\", ascending=True)\n","#sorted_df"],"metadata":{"id":"qcJAw7RGhin9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create CSV from pandas df\n","#sorted_df.to_csv(\"my_submission.csv\",index=False)"],"metadata":{"id":"ZoHXHB2_fWD3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#len(sorted_df)"],"metadata":{"id":"9INY6NvCgObA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Extra curriculum challenge 5 - Use ensemble predictions to get the majority vote (mode) of all the models\n","\n","#models: model_0, model_1, model_2, model_3, model_4, model_5, model_6, model_6_trainable, model_6_full, model_7\n","\n","# check scikit-learn version\n","import sklearn\n","from sklearn.ensemble import VotingClassifier\n","#print(sklearn.__version__)\n","\n","models = [(\"model_1_dense\", model_1), (\"pipeline\", model_0)]\n","ensemble = VotingClassifier(estimators=models, voting=\"soft\")\n","\n","print(ensemble)\n","\n","\n","ensemble.fit(train_sentences, train_labels)"],"metadata":{"id":"uADBL4YFkFp-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.ensemble import VotingClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.svm import SVC\n","\n","estimators = []\n","log_reg = LogisticRegression(solver='liblinear')\n","estimators.append(('Logistic', log_reg))\n","\n","tree = DecisionTreeClassifier()\n","estimators.append(('Tree', tree))\n","\n","svm_clf = SVC(gamma='scale')\n","estimators.append(('SVM', svm_clf))\n","\n","voting = VotingClassifier(estimators=estimators)\n","voting.fit(train_sentences, train_labels)"],"metadata":{"id":"ribjwL7AvEie"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Extracurricular challenge #6: Make a confusion matrix with the best performing model's predictions\n","# on the validation set and the validation ground truth labels.\n","\n","make_confusion_matrix(val_labels, model_6_preds)"],"metadata":{"id":"2GXWyX7m01Rj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uDrNw8_XE2Xd"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1QhfnPWAJm3-X3xT2RPTiHvVp-Y6PRxRJ","timestamp":1706408998737}],"authorship_tag":"ABX9TyNxYNalN0A4Ga6yZYUijDsF"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}